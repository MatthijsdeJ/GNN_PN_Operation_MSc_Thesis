paths:
  rte_case14_realistic: data/rte_case14_realistic/
  rte_case14_realistic_chronics: data/rte_case14_realistic/chronics/
  medha_imitation: data/medha_imitation_sample/
  tutor_imitation: data/greedy_combined_data/
  processed_tutor_imitation: data/processed_greedy_combined_data/
  action_space: action_space/
  con_matrix_cache: data/auxiliary_data_objects/combined_con_matrix_cache.json
  feature_statistics: data/auxiliary_data_objects/combined_feature_statistics.json
  wandb: data/wandb/
  model: models/error_analysis
  evaluation_log: data/evaluation/test.log

evaluation:
  disable_line: -1 # Index of line to be disabled; -1 indicates no line
  n_chronics: 50  # Number of chronics to evaluate
  seed: 1 # Environment seed
  save_data: false # Whether to save action datapoinst
  activity_threshold: 0.97 # Threshold below which agents take do-nothing actions; also used as a threshold for logging
  strategy: verify_greedy_hybrid
  NMinusOne_strategy:
    N0_rho_threshold: 1.0 # N-0 rho robustness threshold
    line_idxs_to_consider_N-1: [0, 1, 2, 3, 4, 5, 6, 10, 12, 13, 15, 16, 19] # Lines to consider in N-1 calculations
  verify_strategy:
    reject_action_threshold: 1.0 # Threshold for the simulated max. rho of action, above which it is rejected
  hybrid_strategies:
    take_the_wheel_threshold: 1.0 # Threshold below which the ML model takes actions for the hybrid agents

rte_case14_realistic:
  thermal_limits: [1000,1000,1000,1000,1000,1000,1000, 760,450, 760,381,380,760,380,760,380,380,380,2000,2000]
  ts_in_day: 288 #Number of timesteps in a grid2op day
  n_subs: 14
  sub_info: [3, 6, 4, 6, 5, 6, 3, 2, 5, 3, 3, 3, 4, 3]
  gen_pos_topo_vect: [ 7, 11, 28, 34,  2]
  load_pos_topo_vect: [ 8, 12, 18, 23, 29, 39, 42, 45, 48, 52, 55]
  line_or_pos_topo_vect: [ 0,  1,  4,  5,  6, 10, 15, 24, 25, 26, 35, 36, 41, 47, 51, 16, 17, 22, 31, 38]
  line_ex_pos_topo_vect: [ 3, 19,  9, 13, 20, 14, 21, 43, 46, 49, 40, 53, 44, 50, 54, 30, 37, 27, 33, 32]

dataset:
  train_perc: 0.7 #Percentage of the files used in the training set
  val_perc: 0.15 #Percentage of the files validation set
  #Remainder is used in the test set
  exclude_chronics: [310, 446, 777] #chronics not included in the dataset
  number_of_datafiles: 7000 #amount of files with datapoints

training:
  settings:
    train_log_freq: 2000 #How often to log the training set statistics
    val_log_freq: 20000 #How often to evaluate the validation set
    dp_per_val_log: 5000 # How many datapoints to use per val logging
    advanced_val_analysis: true
    line_outages_considered: [-1, 0, 1, 2, 3, 4, 5, 6]
  hyperparams:
    model_type: GCN  #Should be GCN or FCNN
    n_epoch: 100
    lr: 5.0E-4
    N_node_hidden: 128 #Size of hidden layers in model
    LReLu_neg_slope: 0.1
    batch_size: 64
    label_smoothing_alpha: 0 #Controls the extent of label smoothing
    weight_init_std: 3
    weight_decay: 0
    early_stopping_patience: 50 #stop training when max. val. macro accuracy
    #valid hasn't improved
    label_weights:
      type: Y_AND_P
      non_masked_weight: 0.1
  constants:
    estimated_train_size: 36497 #Used for estimating tqdm duration
  GCN:
    hyperparams:
      network_type: heterogeneous #Should be a str as defined in training.models.GCN.NetworkType
      N_GCN_layers: 8
      aggr: add #Aggregation function: should be 'add' or 'mean'
      layer_type: SAGEConv
      GINConv_nn_depth : 2
    constants:
      N_f_gen: 3 #Number of generator features
      N_f_load: 3 #Number of load features
      N_f_endpoint: 6 #Number of endpoint (origin/extremity) features
  FCNN:
    hyperparams:
      N_layers: 4
    constants:
      size_in: 344
      size_out: 56
  wandb:
    model_name: test #GCN_test_diff_label_weights
    model_tags: [test] #[GCN, different_label_weights]
    group: null
    project: msc_thesis_gnn_power
    entity: mattholomew
    mode: online
