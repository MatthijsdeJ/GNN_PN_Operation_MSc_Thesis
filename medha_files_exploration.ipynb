{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickletools\n",
    "from grid2op import Episode\n",
    "from collections import namedtuple, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH='./Preliminary_sample/episodes_data/data/raw/grid2op1.0.0/Run_100_2hl_grid2op1.0.0/training_episodes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [DATA_PATH +'/' + f for f in os.listdir(DATA_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(data,most_common_amount=100):\n",
    "    print(f'Total reward: {data.reward}')\n",
    "    print(f'Number of episode steps: {len(data.steps)}')\n",
    "    print(f'Most frequent actions: {Counter([d.action for d in data.steps]).most_common(most_common_amount)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_files[60], 'rb') as f:\n",
    "    data_60 = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data consists of two elements:\n",
    "- Total reward\n",
    "- The list of episode steps\n",
    "\n",
    "Each episode step consist of:\n",
    "- The observation\n",
    "- The chosen action (always 100?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF 0\n",
      "Total reward: 29234.388829231262\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "Total reward: 29234.388829231262\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "\n",
      "DF 1\n",
      "Total reward: 29178.14587211609\n",
      "Number of episode steps: 173\n",
      "Most frequent actions: [(100, 153), (50, 12), (22, 6), (110, 1), (20, 1)]\n",
      "Total reward: 29178.14587211609\n",
      "Number of episode steps: 173\n",
      "Most frequent actions: [(100, 153), (50, 12), (22, 6), (110, 1), (20, 1)]\n",
      "\n",
      "DF 2\n",
      "Total reward: 29234.36419391632\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 2), (103, 1)]\n",
      "Total reward: 29234.36419391632\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 2), (103, 1)]\n",
      "\n",
      "DF 3\n",
      "Total reward: 29237.963020324707\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 183), (50, 5)]\n",
      "Total reward: 29237.963020324707\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 183), (50, 5)]\n",
      "\n",
      "DF 4\n",
      "Total reward: 29236.700632095337\n",
      "Number of episode steps: 204\n",
      "Most frequent actions: [(100, 202), (50, 2)]\n",
      "Total reward: 29236.700632095337\n",
      "Number of episode steps: 204\n",
      "Most frequent actions: [(100, 202), (50, 2)]\n",
      "\n",
      "DF 5\n",
      "Total reward: 29239.116638183594\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 173), (50, 2)]\n",
      "Total reward: 29239.116638183594\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 173), (50, 2)]\n",
      "\n",
      "DF 6\n",
      "Total reward: 29234.504037857056\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "Total reward: 29234.504037857056\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "\n",
      "DF 7\n",
      "Total reward: 29238.06897354126\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29238.06897354126\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 8\n",
      "Total reward: 29232.347950935364\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29232.347950935364\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 9\n",
      "Total reward: 29233.985319137573\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "Total reward: 29233.985319137573\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "\n",
      "DF 10\n",
      "Total reward: 29237.31163597107\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "Total reward: 29237.31163597107\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "\n",
      "DF 11\n",
      "Total reward: 29237.7891998291\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29237.7891998291\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 12\n",
      "Total reward: 29237.37223625183\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "Total reward: 29237.37223625183\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "\n",
      "DF 13\n",
      "Total reward: 29231.828364372253\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 218), (50, 3)]\n",
      "Total reward: 29231.828364372253\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 218), (50, 3)]\n",
      "\n",
      "DF 14\n",
      "Total reward: 29233.775233268738\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "Total reward: 29233.775233268738\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "\n",
      "DF 15\n",
      "Total reward: 29231.58496952057\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.58496952057\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 16\n",
      "Total reward: 29232.30646419525\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29232.30646419525\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 17\n",
      "Total reward: 29234.271997451782\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "Total reward: 29234.271997451782\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "\n",
      "DF 18\n",
      "Total reward: 29231.668274879456\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.668274879456\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 19\n",
      "Total reward: 29226.55762195587\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 169), (50, 13), (106, 1), (22, 1)]\n",
      "Total reward: 29226.55762195587\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 169), (50, 13), (106, 1), (22, 1)]\n",
      "\n",
      "DF 20\n",
      "Total reward: 29225.759744644165\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 194), (50, 2), (22, 1)]\n",
      "Total reward: 29225.759744644165\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 194), (50, 2), (22, 1)]\n",
      "\n",
      "DF 21\n",
      "Total reward: 29209.870797157288\n",
      "Number of episode steps: 209\n",
      "Most frequent actions: [(100, 183), (50, 17), (22, 6), (110, 2), (25, 1)]\n",
      "Total reward: 29209.870797157288\n",
      "Number of episode steps: 209\n",
      "Most frequent actions: [(100, 183), (50, 17), (22, 6), (110, 2), (25, 1)]\n",
      "\n",
      "DF 22\n",
      "Total reward: 29202.914944648743\n",
      "Number of episode steps: 169\n",
      "Most frequent actions: [(100, 150), (50, 10), (22, 6), (106, 2), (58, 1)]\n",
      "Total reward: 29202.914944648743\n",
      "Number of episode steps: 169\n",
      "Most frequent actions: [(100, 150), (50, 10), (22, 6), (106, 2), (58, 1)]\n",
      "\n",
      "DF 23\n",
      "Total reward: 29237.28207397461\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 191), (50, 5), (103, 1), (106, 1)]\n",
      "Total reward: 29237.28207397461\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 191), (50, 5), (103, 1), (106, 1)]\n",
      "\n",
      "DF 24\n",
      "Total reward: 29230.781580924988\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.781580924988\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 25\n",
      "Total reward: 29230.59931087494\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.59931087494\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 26\n",
      "Total reward: 29249.438895225525\n",
      "Number of episode steps: 170\n",
      "Most frequent actions: [(100, 154), (50, 16)]\n",
      "Total reward: 29249.438895225525\n",
      "Number of episode steps: 170\n",
      "Most frequent actions: [(100, 154), (50, 16)]\n",
      "\n",
      "DF 27\n",
      "Total reward: 29236.434337615967\n",
      "Number of episode steps: 211\n",
      "Most frequent actions: [(100, 210), (50, 1)]\n",
      "Total reward: 29236.434337615967\n",
      "Number of episode steps: 211\n",
      "Most frequent actions: [(100, 210), (50, 1)]\n",
      "\n",
      "DF 28\n",
      "Total reward: 29234.152972221375\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "Total reward: 29234.152972221375\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "\n",
      "DF 29\n",
      "Total reward: 29234.33090686798\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "Total reward: 29234.33090686798\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "\n",
      "DF 30\n",
      "Total reward: 29236.40410041809\n",
      "Number of episode steps: 212\n",
      "Most frequent actions: [(100, 210), (50, 2)]\n",
      "Total reward: 29236.40410041809\n",
      "Number of episode steps: 212\n",
      "Most frequent actions: [(100, 210), (50, 2)]\n",
      "\n",
      "DF 31\n",
      "Total reward: 29204.740189552307\n",
      "Number of episode steps: 219\n",
      "Most frequent actions: [(100, 216), (50, 2), (58, 1)]\n",
      "Total reward: 29204.740189552307\n",
      "Number of episode steps: 219\n",
      "Most frequent actions: [(100, 216), (50, 2), (58, 1)]\n",
      "\n",
      "DF 32\n",
      "Total reward: 29237.43430519104\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29237.43430519104\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 33\n",
      "Total reward: 29231.040828704834\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29231.040828704834\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 34\n",
      "Total reward: 29228.157690048218\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.157690048218\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 35\n",
      "Total reward: 29230.25818347931\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.25818347931\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 36\n",
      "Total reward: 29230.176705360413\n",
      "Number of episode steps: 223\n",
      "Most frequent actions: [(100, 222), (50, 1)]\n",
      "Total reward: 29230.176705360413\n",
      "Number of episode steps: 223\n",
      "Most frequent actions: [(100, 222), (50, 1)]\n",
      "\n",
      "DF 37\n",
      "Total reward: 29238.840871810913\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "Total reward: 29238.840871810913\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "\n",
      "DF 38\n",
      "Total reward: 29237.495580673218\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "Total reward: 29237.495580673218\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "\n",
      "DF 39\n",
      "Total reward: 29238.370862960815\n",
      "Number of episode steps: 183\n",
      "Most frequent actions: [(100, 181), (50, 2)]\n",
      "Total reward: 29238.370862960815\n",
      "Number of episode steps: 183\n",
      "Most frequent actions: [(100, 181), (50, 2)]\n",
      "\n",
      "DF 40\n",
      "Total reward: 29228.36954975128\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.36954975128\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 41\n",
      "Total reward: 29237.25542640686\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 187), (50, 2)]\n",
      "Total reward: 29237.25542640686\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 187), (50, 2)]\n",
      "\n",
      "DF 42\n",
      "Total reward: 29230.414103507996\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.414103507996\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 43\n",
      "Total reward: 29229.98441028595\n",
      "Number of episode steps: 230\n",
      "Most frequent actions: [(100, 229), (50, 1)]\n",
      "Total reward: 29229.98441028595\n",
      "Number of episode steps: 230\n",
      "Most frequent actions: [(100, 229), (50, 1)]\n",
      "\n",
      "DF 44\n",
      "Total reward: 29230.718760490417\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.718760490417\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 45\n",
      "Total reward: 29237.283792495728\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 184), (50, 5)]\n",
      "Total reward: 29237.283792495728\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 184), (50, 5)]\n",
      "\n",
      "DF 46\n",
      "Total reward: 29236.491312026978\n",
      "Number of episode steps: 209\n",
      "Most frequent actions: [(100, 208), (50, 1)]\n",
      "Total reward: 29236.491312026978\n",
      "Number of episode steps: 209\n",
      "Most frequent actions: [(100, 208), (50, 1)]\n",
      "\n",
      "DF 47\n",
      "Total reward: 29232.38582134247\n",
      "Number of episode steps: 220\n",
      "Most frequent actions: [(100, 218), (50, 2)]\n",
      "Total reward: 29232.38582134247\n",
      "Number of episode steps: 220\n",
      "Most frequent actions: [(100, 218), (50, 2)]\n",
      "\n",
      "DF 48\n",
      "Total reward: 28947.617058753967\n",
      "Number of episode steps: 159\n",
      "Most frequent actions: [(100, 140), (50, 12), (22, 4), (49, 1), (27, 1), (106, 1)]\n",
      "Total reward: 28947.617058753967\n",
      "Number of episode steps: 159\n",
      "Most frequent actions: [(100, 140), (50, 12), (22, 4), (49, 1), (27, 1), (106, 1)]\n",
      "\n",
      "DF 49\n",
      "Total reward: 29236.762660980225\n",
      "Number of episode steps: 202\n",
      "Most frequent actions: [(100, 198), (50, 4)]\n",
      "Total reward: 29236.762660980225\n",
      "Number of episode steps: 202\n",
      "Most frequent actions: [(100, 198), (50, 4)]\n",
      "\n",
      "DF 50\n",
      "Total reward: 29231.752742767334\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.752742767334\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 51\n",
      "Total reward: 29242.176768302917\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 168), (50, 7), (106, 2), (22, 1), (49, 1), (110, 1), (12, 1)]\n",
      "Total reward: 29242.176768302917\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 168), (50, 7), (106, 2), (22, 1), (49, 1), (110, 1), (12, 1)]\n",
      "\n",
      "DF 52\n",
      "Total reward: 29234.61125946045\n",
      "Number of episode steps: 213\n",
      "Most frequent actions: [(100, 212), (50, 1)]\n",
      "Total reward: 29234.61125946045\n",
      "Number of episode steps: 213\n",
      "Most frequent actions: [(100, 212), (50, 1)]\n",
      "\n",
      "DF 53\n",
      "Total reward: 29237.85761833191\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 181), (50, 7)]\n",
      "Total reward: 29237.85761833191\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 181), (50, 7)]\n",
      "\n",
      "DF 54\n",
      "Total reward: 29237.142992019653\n",
      "Number of episode steps: 190\n",
      "Most frequent actions: [(100, 189), (50, 1)]\n",
      "Total reward: 29237.142992019653\n",
      "Number of episode steps: 190\n",
      "Most frequent actions: [(100, 189), (50, 1)]\n",
      "\n",
      "DF 55\n",
      "Total reward: 29231.342646598816\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 216), (50, 5)]\n",
      "Total reward: 29231.342646598816\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 216), (50, 5)]\n",
      "\n",
      "DF 56\n",
      "Total reward: 29225.71441078186\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 192), (50, 4), (22, 1)]\n",
      "Total reward: 29225.71441078186\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 192), (50, 4), (22, 1)]\n",
      "\n",
      "DF 57\n",
      "Total reward: 29236.856698989868\n",
      "Number of episode steps: 199\n",
      "Most frequent actions: [(100, 198), (50, 1)]\n",
      "Total reward: 29236.856698989868\n",
      "Number of episode steps: 199\n",
      "Most frequent actions: [(100, 198), (50, 1)]\n",
      "\n",
      "DF 58\n",
      "Total reward: 29230.749693870544\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.749693870544\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 59\n",
      "Total reward: 29228.347060203552\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 176), (50, 4), (22, 1)]\n",
      "Total reward: 29228.347060203552\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 176), (50, 4), (22, 1)]\n",
      "\n",
      "DF 60\n",
      "Total reward: 29227.99485206604\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 177), (50, 11), (22, 1)]\n",
      "Total reward: 29227.99485206604\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 177), (50, 11), (22, 1)]\n",
      "\n",
      "DF 61\n",
      "Total reward: 29237.823154449463\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29237.823154449463\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 62\n",
      "Total reward: 29239.069493293762\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 173), (50, 2)]\n",
      "Total reward: 29239.069493293762\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 173), (50, 2)]\n",
      "\n",
      "DF 63\n",
      "Total reward: 29228.270020484924\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.270020484924\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 64\n",
      "Total reward: 29230.506972312927\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.506972312927\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 65\n",
      "Total reward: 29236.91812133789\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 195), (50, 2)]\n",
      "Total reward: 29236.91812133789\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 195), (50, 2)]\n",
      "\n",
      "DF 66\n",
      "Total reward: 29237.754245758057\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29237.754245758057\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 67\n",
      "Total reward: 29237.035564422607\n",
      "Number of episode steps: 194\n",
      "Most frequent actions: [(100, 193), (50, 1)]\n",
      "Total reward: 29237.035564422607\n",
      "Number of episode steps: 194\n",
      "Most frequent actions: [(100, 193), (50, 1)]\n",
      "\n",
      "DF 68\n",
      "Total reward: 29231.50314426422\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 29231.50314426422\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 69\n",
      "Total reward: 29236.46312713623\n",
      "Number of episode steps: 210\n",
      "Most frequent actions: [(100, 208), (50, 2)]\n",
      "Total reward: 29236.46312713623\n",
      "Number of episode steps: 210\n",
      "Most frequent actions: [(100, 208), (50, 2)]\n",
      "\n",
      "DF 70\n",
      "Total reward: 29238.337060928345\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 179), (50, 4), (106, 1)]\n",
      "Total reward: 29238.337060928345\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 179), (50, 4), (106, 1)]\n",
      "\n",
      "DF 71\n",
      "Total reward: 29237.06489944458\n",
      "Number of episode steps: 193\n",
      "Most frequent actions: [(100, 191), (50, 2)]\n",
      "Total reward: 29237.06489944458\n",
      "Number of episode steps: 193\n",
      "Most frequent actions: [(100, 191), (50, 2)]\n",
      "\n",
      "DF 72\n",
      "Total reward: 29230.4468126297\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.4468126297\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 73\n",
      "Total reward: 29225.407821655273\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 190), (50, 6), (22, 1)]\n",
      "Total reward: 29225.407821655273\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 190), (50, 6), (22, 1)]\n",
      "\n",
      "DF 74\n",
      "Total reward: 29237.46511077881\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "Total reward: 29237.46511077881\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "\n",
      "DF 75\n",
      "Total reward: 29238.536630630493\n",
      "Number of episode steps: 177\n",
      "Most frequent actions: [(100, 171), (50, 5), (106, 1)]\n",
      "Total reward: 29238.536630630493\n",
      "Number of episode steps: 177\n",
      "Most frequent actions: [(100, 171), (50, 5), (106, 1)]\n",
      "\n",
      "DF 76\n",
      "Total reward: 29230.640495300293\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 180), (32, 1), (50, 1)]\n",
      "Total reward: 29230.640495300293\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 180), (32, 1), (50, 1)]\n",
      "\n",
      "DF 77\n",
      "Total reward: 29238.400617599487\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 178), (50, 4)]\n",
      "Total reward: 29238.400617599487\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 178), (50, 4)]\n",
      "\n",
      "DF 78\n",
      "Total reward: 29233.635521888733\n",
      "Number of episode steps: 216\n",
      "Most frequent actions: [(100, 214), (50, 2)]\n",
      "Total reward: 29233.635521888733\n",
      "Number of episode steps: 216\n",
      "Most frequent actions: [(100, 214), (50, 2)]\n",
      "\n",
      "DF 79\n",
      "Total reward: 29229.957648277283\n",
      "Number of episode steps: 231\n",
      "Most frequent actions: [(100, 230), (50, 1)]\n",
      "Total reward: 29229.957648277283\n",
      "Number of episode steps: 231\n",
      "Most frequent actions: [(100, 230), (50, 1)]\n",
      "\n",
      "DF 80\n",
      "Total reward: 29233.59268283844\n",
      "Number of episode steps: 217\n",
      "Most frequent actions: [(100, 216), (50, 1)]\n",
      "Total reward: 29233.59268283844\n",
      "Number of episode steps: 217\n",
      "Most frequent actions: [(100, 216), (50, 1)]\n",
      "\n",
      "DF 81\n",
      "Total reward: 29230.942784309387\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.942784309387\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 82\n",
      "Total reward: 29238.60414505005\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 170), (50, 5)]\n",
      "Total reward: 29238.60414505005\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 170), (50, 5)]\n",
      "\n",
      "DF 83\n",
      "Total reward: 29238.883556365967\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 164), (50, 11)]\n",
      "Total reward: 29238.883556365967\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 164), (50, 11)]\n",
      "\n",
      "DF 84\n",
      "Total reward: 29238.03518486023\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29238.03518486023\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 85\n",
      "Total reward: 29237.1327085495\n",
      "Number of episode steps: 179\n",
      "Most frequent actions: [(100, 169), (50, 9), (22, 1)]\n",
      "Total reward: 29237.1327085495\n",
      "Number of episode steps: 179\n",
      "Most frequent actions: [(100, 169), (50, 9), (22, 1)]\n",
      "\n",
      "DF 86\n",
      "Total reward: 29236.578247070312\n",
      "Number of episode steps: 207\n",
      "Most frequent actions: [(100, 206), (50, 1)]\n",
      "Total reward: 29236.578247070312\n",
      "Number of episode steps: 207\n",
      "Most frequent actions: [(100, 206), (50, 1)]\n",
      "\n",
      "DF 87\n",
      "Total reward: 29230.629775047302\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.629775047302\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 88\n",
      "Total reward: 29230.381335258484\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.381335258484\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 89\n",
      "Total reward: 29237.402647018433\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29237.402647018433\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 90\n",
      "Total reward: 29225.572828292847\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 194), (50, 2), (22, 1)]\n",
      "Total reward: 29225.572828292847\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 194), (50, 2), (22, 1)]\n",
      "\n",
      "DF 91\n",
      "Total reward: 29238.568977355957\n",
      "Number of episode steps: 176\n",
      "Most frequent actions: [(100, 171), (50, 5)]\n",
      "Total reward: 29238.568977355957\n",
      "Number of episode steps: 176\n",
      "Most frequent actions: [(100, 171), (50, 5)]\n",
      "\n",
      "DF 92\n",
      "Total reward: 29238.640590667725\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 170), (50, 5)]\n",
      "Total reward: 29238.640590667725\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 170), (50, 5)]\n",
      "\n",
      "DF 93\n",
      "Total reward: 29237.894262313843\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29237.894262313843\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 94\n",
      "Total reward: 29239.16575527191\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "Total reward: 29239.16575527191\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "\n",
      "DF 95\n",
      "Total reward: 29230.013445854187\n",
      "Number of episode steps: 229\n",
      "Most frequent actions: [(100, 228), (50, 1)]\n",
      "Total reward: 29230.013445854187\n",
      "Number of episode steps: 229\n",
      "Most frequent actions: [(100, 228), (50, 1)]\n",
      "\n",
      "DF 96\n",
      "Total reward: 29237.9985332489\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29237.9985332489\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 97\n",
      "Total reward: 29238.27082633972\n",
      "Number of episode steps: 185\n",
      "Most frequent actions: [(100, 184), (50, 1)]\n",
      "Total reward: 29238.27082633972\n",
      "Number of episode steps: 185\n",
      "Most frequent actions: [(100, 184), (50, 1)]\n",
      "\n",
      "DF 98\n",
      "Total reward: 29237.653675079346\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 179), (50, 8), (25, 1)]\n",
      "Total reward: 29237.653675079346\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 179), (50, 8), (25, 1)]\n",
      "\n",
      "DF 99\n",
      "Total reward: 29237.722579956055\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "Total reward: 29237.722579956055\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "\n",
      "DF 100\n",
      "Total reward: 29237.199851989746\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 188), (50, 1)]\n",
      "Total reward: 29237.199851989746\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 188), (50, 1)]\n",
      "\n",
      "DF 101\n",
      "Total reward: 29228.448823928833\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 178), (50, 8), (110, 1), (0, 1), (22, 1)]\n",
      "Total reward: 29228.448823928833\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 178), (50, 8), (110, 1), (0, 1), (22, 1)]\n",
      "\n",
      "DF 102\n",
      "Total reward: 29238.75616455078\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "Total reward: 29238.75616455078\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "\n",
      "DF 103\n",
      "Total reward: 29229.00342464447\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 172), (50, 8), (22, 1)]\n",
      "Total reward: 29229.00342464447\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 172), (50, 8), (22, 1)]\n",
      "\n",
      "DF 104\n",
      "Total reward: 28886.299180030823\n",
      "Number of episode steps: 142\n",
      "Most frequent actions: [(100, 113), (50, 20), (22, 5), (110, 2), (27, 1), (106, 1)]\n",
      "Total reward: 28886.299180030823\n",
      "Number of episode steps: 142\n",
      "Most frequent actions: [(100, 113), (50, 20), (22, 5), (110, 2), (27, 1), (106, 1)]\n",
      "\n",
      "DF 105\n",
      "Total reward: 29237.11675643921\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 189), (50, 2)]\n",
      "Total reward: 29237.11675643921\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 189), (50, 2)]\n",
      "\n",
      "DF 106\n",
      "Total reward: 29241.902285575867\n",
      "Number of episode steps: 171\n",
      "Most frequent actions: [(100, 167), (50, 4)]\n",
      "Total reward: 29241.902285575867\n",
      "Number of episode steps: 171\n",
      "Most frequent actions: [(100, 167), (50, 4)]\n",
      "\n",
      "DF 107\n",
      "Total reward: 29237.686807632446\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "Total reward: 29237.686807632446\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 3)]\n",
      "\n",
      "DF 108\n",
      "Total reward: 29233.931030273438\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "Total reward: 29233.931030273438\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "\n",
      "DF 109\n",
      "Total reward: 29237.006286621094\n",
      "Number of episode steps: 194\n",
      "Most frequent actions: [(100, 192), (50, 2)]\n",
      "Total reward: 29237.006286621094\n",
      "Number of episode steps: 194\n",
      "Most frequent actions: [(100, 192), (50, 2)]\n",
      "\n",
      "DF 110\n",
      "Total reward: 29236.669647216797\n",
      "Number of episode steps: 205\n",
      "Most frequent actions: [(100, 201), (50, 4)]\n",
      "Total reward: 29236.669647216797\n",
      "Number of episode steps: 205\n",
      "Most frequent actions: [(100, 201), (50, 4)]\n",
      "\n",
      "DF 111\n",
      "Total reward: 29226.74903869629\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 175), (50, 7), (110, 1), (22, 1)]\n",
      "Total reward: 29226.74903869629\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 175), (50, 7), (110, 1), (22, 1)]\n",
      "\n",
      "DF 112\n",
      "Total reward: 29226.5303440094\n",
      "Number of episode steps: 203\n",
      "Most frequent actions: [(100, 197), (50, 5), (22, 1)]\n",
      "Total reward: 29226.5303440094\n",
      "Number of episode steps: 203\n",
      "Most frequent actions: [(100, 197), (50, 5), (22, 1)]\n",
      "\n",
      "DF 113\n",
      "Total reward: 29239.213103294373\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "Total reward: 29239.213103294373\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "\n",
      "DF 114\n",
      "Total reward: 29232.422905921936\n",
      "Number of episode steps: 219\n",
      "Most frequent actions: [(100, 216), (50, 3)]\n",
      "Total reward: 29232.422905921936\n",
      "Number of episode steps: 219\n",
      "Most frequent actions: [(100, 216), (50, 3)]\n",
      "\n",
      "DF 115\n",
      "Total reward: 29238.200658798218\n",
      "Number of episode steps: 187\n",
      "Most frequent actions: [(100, 185), (50, 2)]\n",
      "Total reward: 29238.200658798218\n",
      "Number of episode steps: 187\n",
      "Most frequent actions: [(100, 185), (50, 2)]\n",
      "\n",
      "DF 116\n",
      "Total reward: 29228.41782283783\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.41782283783\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 117\n",
      "Total reward: 29230.907431602478\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.907431602478\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 118\n",
      "Total reward: 29238.92861366272\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "Total reward: 29238.92861366272\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 174), (50, 1)]\n",
      "\n",
      "DF 119\n",
      "Total reward: 29227.997816085815\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 184), (50, 4), (22, 1)]\n",
      "Total reward: 29227.997816085815\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 184), (50, 4), (22, 1)]\n",
      "\n",
      "DF 120\n",
      "Total reward: 29231.710020065308\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 170), (50, 10), (22, 2), (103, 1), (106, 1)]\n",
      "Total reward: 29231.710020065308\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 170), (50, 10), (22, 2), (103, 1), (106, 1)]\n",
      "\n",
      "DF 121\n",
      "Total reward: 29236.794889450073\n",
      "Number of episode steps: 201\n",
      "Most frequent actions: [(100, 198), (50, 3)]\n",
      "Total reward: 29236.794889450073\n",
      "Number of episode steps: 201\n",
      "Most frequent actions: [(100, 198), (50, 3)]\n",
      "\n",
      "DF 122\n",
      "Total reward: 29228.122995376587\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.122995376587\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 123\n",
      "Total reward: 29231.423281669617\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.423281669617\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 124\n",
      "Total reward: 29236.731534957886\n",
      "Number of episode steps: 203\n",
      "Most frequent actions: [(100, 201), (50, 2)]\n",
      "Total reward: 29236.731534957886\n",
      "Number of episode steps: 203\n",
      "Most frequent actions: [(100, 201), (50, 2)]\n",
      "\n",
      "DF 125\n",
      "Total reward: 28931.09190273285\n",
      "Number of episode steps: 139\n",
      "Most frequent actions: [(100, 134), (50, 3), (106, 1), (27, 1)]\n",
      "Total reward: 28931.09190273285\n",
      "Number of episode steps: 139\n",
      "Most frequent actions: [(100, 134), (50, 3), (106, 1), (27, 1)]\n",
      "\n",
      "DF 126\n",
      "Total reward: 29232.223587989807\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29232.223587989807\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 127\n",
      "Total reward: 29225.730445861816\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 193), (50, 3), (22, 1)]\n",
      "Total reward: 29225.730445861816\n",
      "Number of episode steps: 197\n",
      "Most frequent actions: [(100, 193), (50, 3), (22, 1)]\n",
      "\n",
      "DF 128\n",
      "Total reward: 29228.59125518799\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 178), (50, 8), (22, 2), (103, 1)]\n",
      "Total reward: 29228.59125518799\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 178), (50, 8), (22, 2), (103, 1)]\n",
      "\n",
      "DF 129\n",
      "Total reward: 29231.915236473083\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.915236473083\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 130\n",
      "Total reward: 29237.22703933716\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 185), (50, 4)]\n",
      "Total reward: 29237.22703933716\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 185), (50, 4)]\n",
      "\n",
      "DF 131\n",
      "Total reward: 29239.25780391693\n",
      "Number of episode steps: 174\n",
      "Most frequent actions: [(100, 171), (50, 3)]\n",
      "Total reward: 29239.25780391693\n",
      "Number of episode steps: 174\n",
      "Most frequent actions: [(100, 171), (50, 3)]\n",
      "\n",
      "DF 132\n",
      "Total reward: 29237.090126037598\n",
      "Number of episode steps: 192\n",
      "Most frequent actions: [(100, 189), (50, 3)]\n",
      "Total reward: 29237.090126037598\n",
      "Number of episode steps: 192\n",
      "Most frequent actions: [(100, 189), (50, 3)]\n",
      "\n",
      "DF 133\n",
      "Total reward: 29232.049702644348\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29232.049702644348\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 134\n",
      "Total reward: 29231.152174949646\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29231.152174949646\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 135\n",
      "Total reward: 29231.305375099182\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29231.305375099182\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 136\n",
      "Total reward: 29230.87669658661\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29230.87669658661\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 137\n",
      "Total reward: 29236.97942352295\n",
      "Number of episode steps: 195\n",
      "Most frequent actions: [(100, 191), (50, 4)]\n",
      "Total reward: 29236.97942352295\n",
      "Number of episode steps: 195\n",
      "Most frequent actions: [(100, 191), (50, 4)]\n",
      "\n",
      "DF 138\n",
      "Total reward: 29231.7106924057\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.7106924057\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 139\n",
      "Total reward: 29229.88125896454\n",
      "Number of episode steps: 234\n",
      "Most frequent actions: [(100, 233), (50, 1)]\n",
      "Total reward: 29229.88125896454\n",
      "Number of episode steps: 234\n",
      "Most frequent actions: [(100, 233), (50, 1)]\n",
      "\n",
      "DF 140\n",
      "Total reward: 29231.0070438385\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29231.0070438385\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 141\n",
      "Total reward: 29237.621726989746\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29237.621726989746\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 142\n",
      "Total reward: 29224.509355545044\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 195), (50, 2), (22, 1)]\n",
      "Total reward: 29224.509355545044\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 195), (50, 2), (22, 1)]\n",
      "\n",
      "DF 143\n",
      "Total reward: 29238.973978996277\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "Total reward: 29238.973978996277\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 169), (50, 6)]\n",
      "\n",
      "DF 144\n",
      "Total reward: 29232.093104362488\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29232.093104362488\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 145\n",
      "Total reward: 29218.868107795715\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 161), (50, 16), (22, 10), (106, 1), (92, 1), (110, 1), (12, 1)]\n",
      "Total reward: 29218.868107795715\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 161), (50, 16), (22, 10), (106, 1), (92, 1), (110, 1), (12, 1)]\n",
      "\n",
      "DF 146\n",
      "Total reward: 29238.742199897766\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 167), (50, 15), (22, 1), (65, 1)]\n",
      "Total reward: 29238.742199897766\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 167), (50, 15), (22, 1), (65, 1)]\n",
      "\n",
      "DF 147\n",
      "Total reward: 29229.906546592712\n",
      "Number of episode steps: 233\n",
      "Most frequent actions: [(100, 230), (50, 3)]\n",
      "Total reward: 29229.906546592712\n",
      "Number of episode steps: 233\n",
      "Most frequent actions: [(100, 230), (50, 3)]\n",
      "\n",
      "DF 148\n",
      "Total reward: 29223.635023117065\n",
      "Number of episode steps: 222\n",
      "Most frequent actions: [(100, 219), (50, 2), (22, 1)]\n",
      "Total reward: 29223.635023117065\n",
      "Number of episode steps: 222\n",
      "Most frequent actions: [(100, 219), (50, 2), (22, 1)]\n",
      "\n",
      "DF 149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 29227.54720401764\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 171), (50, 5), (22, 4), (103, 1), (0, 1)]\n",
      "Total reward: 29227.54720401764\n",
      "Number of episode steps: 182\n",
      "Most frequent actions: [(100, 171), (50, 5), (22, 4), (103, 1), (0, 1)]\n",
      "\n",
      "DF 150\n",
      "Total reward: 29231.115439414978\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29231.115439414978\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 151\n",
      "Total reward: 29242.006686210632\n",
      "Number of episode steps: 170\n",
      "Most frequent actions: [(100, 165), (50, 5)]\n",
      "Total reward: 29242.006686210632\n",
      "Number of episode steps: 170\n",
      "Most frequent actions: [(100, 165), (50, 5)]\n",
      "\n",
      "DF 152\n",
      "Total reward: 29233.82650089264\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "Total reward: 29233.82650089264\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 213), (50, 2)]\n",
      "\n",
      "DF 153\n",
      "Total reward: 29239.302178382874\n",
      "Number of episode steps: 173\n",
      "Most frequent actions: [(100, 172), (50, 1)]\n",
      "Total reward: 29239.302178382874\n",
      "Number of episode steps: 173\n",
      "Most frequent actions: [(100, 172), (50, 1)]\n",
      "\n",
      "DF 154\n",
      "Total reward: 29230.65974521637\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.65974521637\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 155\n",
      "Total reward: 29228.506999015808\n",
      "Number of episode steps: 237\n",
      "Most frequent actions: [(100, 236), (50, 1)]\n",
      "Total reward: 29228.506999015808\n",
      "Number of episode steps: 237\n",
      "Most frequent actions: [(100, 236), (50, 1)]\n",
      "\n",
      "DF 156\n",
      "Total reward: 29234.44781780243\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "Total reward: 29234.44781780243\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "\n",
      "DF 157\n",
      "Total reward: 29230.476672172546\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.476672172546\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 158\n",
      "Total reward: 29249.74188518524\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 172), (50, 15), (22, 3), (48, 1)]\n",
      "Total reward: 29249.74188518524\n",
      "Number of episode steps: 191\n",
      "Most frequent actions: [(100, 172), (50, 15), (22, 3), (48, 1)]\n",
      "\n",
      "DF 159\n",
      "Total reward: 29237.58881378174\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29237.58881378174\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 160\n",
      "Total reward: 29236.949783325195\n",
      "Number of episode steps: 196\n",
      "Most frequent actions: [(100, 194), (50, 2)]\n",
      "Total reward: 29236.949783325195\n",
      "Number of episode steps: 196\n",
      "Most frequent actions: [(100, 194), (50, 2)]\n",
      "\n",
      "DF 161\n",
      "Total reward: 29238.428741455078\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 177), (50, 4)]\n",
      "Total reward: 29238.428741455078\n",
      "Number of episode steps: 181\n",
      "Most frequent actions: [(100, 177), (50, 4)]\n",
      "\n",
      "DF 162\n",
      "Total reward: 29238.4571685791\n",
      "Number of episode steps: 180\n",
      "Most frequent actions: [(100, 177), (50, 3)]\n",
      "Total reward: 29238.4571685791\n",
      "Number of episode steps: 180\n",
      "Most frequent actions: [(100, 177), (50, 3)]\n",
      "\n",
      "DF 163\n",
      "Total reward: 29237.928638458252\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 3), (106, 1)]\n",
      "Total reward: 29237.928638458252\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 3), (106, 1)]\n",
      "\n",
      "DF 164\n",
      "Total reward: 29236.88894844055\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 197), (50, 1)]\n",
      "Total reward: 29236.88894844055\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 197), (50, 1)]\n",
      "\n",
      "DF 165\n",
      "Total reward: 29230.316531181335\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29230.316531181335\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 166\n",
      "Total reward: 29211.27648830414\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 159), (50, 20), (22, 14), (110, 3), (103, 1), (12, 1)]\n",
      "Total reward: 29211.27648830414\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 159), (50, 20), (22, 14), (110, 3), (103, 1), (12, 1)]\n",
      "\n",
      "DF 167\n",
      "Total reward: 29232.18061351776\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29232.18061351776\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 168\n",
      "Total reward: 29238.71709060669\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 172), (50, 3)]\n",
      "Total reward: 29238.71709060669\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 172), (50, 3)]\n",
      "\n",
      "DF 169\n",
      "Total reward: 29230.688899040222\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "Total reward: 29230.688899040222\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 219), (50, 2)]\n",
      "\n",
      "DF 170\n",
      "Total reward: 29238.09972000122\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "Total reward: 29238.09972000122\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 186), (50, 2)]\n",
      "\n",
      "DF 171\n",
      "Total reward: 29238.133604049683\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 181), (50, 6), (110, 1)]\n",
      "Total reward: 29238.133604049683\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 181), (50, 6), (110, 1)]\n",
      "\n",
      "DF 172\n",
      "Total reward: 29238.795415878296\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 171), (50, 3), (106, 1)]\n",
      "Total reward: 29238.795415878296\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 171), (50, 3), (106, 1)]\n",
      "\n",
      "DF 173\n",
      "Total reward: 29227.593042373657\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 179), (50, 17), (110, 1), (22, 1)]\n",
      "Total reward: 29227.593042373657\n",
      "Number of episode steps: 198\n",
      "Most frequent actions: [(100, 179), (50, 17), (110, 1), (22, 1)]\n",
      "\n",
      "DF 174\n",
      "Total reward: 29237.525421142578\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 183), (50, 4), (106, 1)]\n",
      "Total reward: 29237.525421142578\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 183), (50, 4), (106, 1)]\n",
      "\n",
      "DF 175\n",
      "Total reward: 29240.777832984924\n",
      "Number of episode steps: 172\n",
      "Most frequent actions: [(100, 167), (50, 5)]\n",
      "Total reward: 29240.777832984924\n",
      "Number of episode steps: 172\n",
      "Most frequent actions: [(100, 167), (50, 5)]\n",
      "\n",
      "DF 176\n",
      "Total reward: 29230.536519050598\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.536519050598\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 177\n",
      "Total reward: 29231.22839832306\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.22839832306\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 178\n",
      "Total reward: 29230.152318000793\n",
      "Number of episode steps: 224\n",
      "Most frequent actions: [(100, 223), (50, 1)]\n",
      "Total reward: 29230.152318000793\n",
      "Number of episode steps: 224\n",
      "Most frequent actions: [(100, 223), (50, 1)]\n",
      "\n",
      "DF 179\n",
      "Total reward: 29234.039729118347\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "Total reward: 29234.039729118347\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 212), (50, 3)]\n",
      "\n",
      "DF 180\n",
      "Total reward: 29236.639322280884\n",
      "Number of episode steps: 206\n",
      "Most frequent actions: [(100, 204), (50, 2)]\n",
      "Total reward: 29236.639322280884\n",
      "Number of episode steps: 206\n",
      "Most frequent actions: [(100, 204), (50, 2)]\n",
      "\n",
      "DF 181\n",
      "Total reward: 29234.559032440186\n",
      "Number of episode steps: 214\n",
      "Most frequent actions: [(100, 211), (50, 3)]\n",
      "Total reward: 29234.559032440186\n",
      "Number of episode steps: 214\n",
      "Most frequent actions: [(100, 211), (50, 3)]\n",
      "\n",
      "DF 182\n",
      "Total reward: 29237.341724395752\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "Total reward: 29237.341724395752\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 187), (50, 1)]\n",
      "\n",
      "DF 183\n",
      "Total reward: 29238.679235458374\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 168), (50, 6), (106, 1)]\n",
      "Total reward: 29238.679235458374\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 168), (50, 6), (106, 1)]\n",
      "\n",
      "DF 184\n",
      "Total reward: 29228.3221616745\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "Total reward: 29228.3221616745\n",
      "Number of episode steps: 239\n",
      "Most frequent actions: [(100, 238), (50, 1)]\n",
      "\n",
      "DF 185\n",
      "Total reward: 29234.212489128113\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "Total reward: 29234.212489128113\n",
      "Number of episode steps: 215\n",
      "Most frequent actions: [(100, 214), (50, 1)]\n",
      "\n",
      "DF 186\n",
      "Total reward: 29231.871022224426\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.871022224426\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 187\n",
      "Total reward: 29233.682059288025\n",
      "Number of episode steps: 216\n",
      "Most frequent actions: [(100, 214), (50, 2)]\n",
      "Total reward: 29233.682059288025\n",
      "Number of episode steps: 216\n",
      "Most frequent actions: [(100, 214), (50, 2)]\n",
      "\n",
      "DF 188\n",
      "Total reward: 29231.38259792328\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 218), (50, 2), (110, 1)]\n",
      "Total reward: 29231.38259792328\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 218), (50, 2), (110, 1)]\n",
      "\n",
      "DF 189\n",
      "Total reward: 29236.52213859558\n",
      "Number of episode steps: 208\n",
      "Most frequent actions: [(100, 206), (50, 2)]\n",
      "Total reward: 29236.52213859558\n",
      "Number of episode steps: 208\n",
      "Most frequent actions: [(100, 206), (50, 2)]\n",
      "\n",
      "DF 190\n",
      "Total reward: 29230.232138633728\n",
      "Number of episode steps: 222\n",
      "Most frequent actions: [(100, 220), (50, 2)]\n",
      "Total reward: 29230.232138633728\n",
      "Number of episode steps: 222\n",
      "Most frequent actions: [(100, 220), (50, 2)]\n",
      "\n",
      "DF 191\n",
      "Total reward: 29231.959710121155\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29231.959710121155\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 192\n",
      "Total reward: 29230.287859916687\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "Total reward: 29230.287859916687\n",
      "Number of episode steps: 221\n",
      "Most frequent actions: [(100, 220), (50, 1)]\n",
      "\n",
      "DF 193\n",
      "Total reward: 29237.557401657104\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 2), (106, 1)]\n",
      "Total reward: 29237.557401657104\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 185), (50, 2), (106, 1)]\n",
      "\n",
      "DF 194\n",
      "Total reward: 29237.169858932495\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 187), (50, 2)]\n",
      "Total reward: 29237.169858932495\n",
      "Number of episode steps: 189\n",
      "Most frequent actions: [(100, 187), (50, 2)]\n",
      "\n",
      "DF 195\n",
      "Total reward: 29238.47569847107\n",
      "Number of episode steps: 179\n",
      "Most frequent actions: [(100, 175), (50, 4)]\n",
      "Total reward: 29238.47569847107\n",
      "Number of episode steps: 179\n",
      "Most frequent actions: [(100, 175), (50, 4)]\n",
      "\n",
      "DF 196\n",
      "Total reward: 29239.021198272705\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 171), (50, 3), (106, 1)]\n",
      "Total reward: 29239.021198272705\n",
      "Number of episode steps: 175\n",
      "Most frequent actions: [(100, 171), (50, 3), (106, 1)]\n",
      "\n",
      "DF 197\n",
      "Total reward: 29238.17000389099\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "Total reward: 29238.17000389099\n",
      "Number of episode steps: 188\n",
      "Most frequent actions: [(100, 184), (50, 4)]\n",
      "\n",
      "DF 198\n",
      "Total reward: 29238.304000854492\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 179), (50, 5)]\n",
      "Total reward: 29238.304000854492\n",
      "Number of episode steps: 184\n",
      "Most frequent actions: [(100, 179), (50, 5)]\n",
      "\n",
      "DF 199\n",
      "Total reward: 29238.50569343567\n",
      "Number of episode steps: 178\n",
      "Most frequent actions: [(100, 172), (50, 5), (110, 1)]\n",
      "Total reward: 29238.50569343567\n",
      "Number of episode steps: 178\n",
      "Most frequent actions: [(100, 172), (50, 5), (110, 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for i,df in enumerate(data_files):\n",
    "    print(f'DF {i}')\n",
    "    with open(df, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        print_data_info(data)\n",
    "    print_data_info(data)\n",
    "    print('')\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_per_episodes =  [d.reward for d in data_list]\n",
    "steps_per_episodes =  [len(d.steps) for d in data_list]\n",
    "def flatten(t): return [item for sublist in t for item in sublist]\n",
    "actions_distribution =  flatten([[s.action for s in d.steps] for d in data_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "axs[0].hist(reward_per_episodes,bins=100)\n",
    "axs[0].set_title('Reward distribution')\n",
    "axs[1].hist(steps_per_episodes,bins=100)\n",
    "axs[1].set_title('Number of steps distribution')\n",
    "axs[2].hist(actions_distribution,bins=100)\n",
    "axs[2].set_title('Action distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.observation for s in data_60.steps][0][-96:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s.observation for s in data_60.steps][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.44000015e+01,  7.45999985e+01,  3.49000015e+01,  2.00000003e-01,\n",
       "        7.69650574e+01,  2.06861515e+01,  7.50823746e+01,  4.76640549e+01,\n",
       "        2.61155167e+01, -1.72150040e+01,  1.42100006e+02,  1.42100006e+02,\n",
       "        2.20000000e+01,  1.32000008e+01,  1.42100006e+02,  2.27999992e+01,\n",
       "        8.78000031e+01,  4.62000008e+01,  7.59999990e+00,  1.18999996e+01,\n",
       "        3.15000000e+01,  9.19999981e+00,  3.70000005e+00,  6.30000019e+00,\n",
       "        1.41000004e+01,  1.58999996e+01,  1.58999996e+01,  6.14000015e+01,\n",
       "        3.20999985e+01,  5.19999981e+00,  8.50000000e+00,  2.22000008e+01,\n",
       "        6.40000010e+00,  2.59999990e+00,  4.50000000e+00,  9.80000019e+00,\n",
       "        1.11999998e+01,  1.42100006e+02,  1.42100006e+02,  1.38739517e+02,\n",
       "        1.39560150e+02,  2.20000000e+01,  2.09746780e+01,  2.09852562e+01,\n",
       "        2.13917923e+01,  2.15145454e+01,  2.13527489e+01,  2.05783176e+01,\n",
       "        4.17312355e+01,  3.52338219e+01,  2.52821007e+01,  3.76640167e+01,\n",
       "        3.00355530e+01,  1.17861767e+01, -3.32857895e+01,  1.45653477e+01,\n",
       "        9.17162418e+00,  2.23790493e+01, -1.30629933e+00,  5.60785866e+00,\n",
       "       -1.05068007e+01,  2.74871397e+00,  1.05949574e+01,  2.26550503e+01,\n",
       "        1.29465094e+01,  2.31160183e+01, -2.00000003e-01, -2.28550491e+01,\n",
       "       -1.58765821e+01, -1.33842230e+00, -7.66452456e+00,  1.15318716e+00,\n",
       "       -4.79682907e-02,  9.41525745e+00, -3.43005729e+00,  9.94432831e+00,\n",
       "        6.07301807e+00,  1.60751686e+01, -1.63925454e-01,  5.06362581e+00,\n",
       "       -6.56525707e+00,  1.31720757e+00,  6.75892973e+00, -1.43544941e+01,\n",
       "       -1.66267478e+00, -5.85443544e+00, -2.51225834e+01, -8.74565887e+00,\n",
       "        1.42100006e+02,  1.42100006e+02,  1.42100006e+02,  1.42100006e+02,\n",
       "        1.42100006e+02,  1.42100006e+02,  1.38739517e+02,  2.20000000e+01,\n",
       "        2.20000000e+01,  2.20000000e+01,  2.09746780e+01,  2.09746780e+01,\n",
       "        2.09852562e+01,  2.15145454e+01,  2.13527489e+01,  1.38739517e+02,\n",
       "        1.38739517e+02,  1.39560150e+02,  1.48145142e+01,  2.09746780e+01,\n",
       "        1.81409546e+02,  1.43257767e+02,  1.07337402e+02,  1.53100067e+02,\n",
       "        1.22034172e+02,  6.12906532e+01,  1.39248901e+02,  4.62832794e+02,\n",
       "        2.88675415e+02,  7.23109680e+02,  3.62392807e+01,  2.07978241e+02,\n",
       "        3.40857513e+02,  8.17948456e+01,  3.39802429e+02,  1.11607925e+02,\n",
       "        5.43180466e+01,  9.86485748e+01,  9.79106689e+02,  6.73595825e+02,\n",
       "       -4.13816681e+01, -3.46004066e+01, -2.49861813e+01, -3.68817749e+01,\n",
       "       -2.95492935e+01, -1.16339941e+01,  3.34336815e+01, -1.43211946e+01,\n",
       "       -9.04871464e+00, -2.19639797e+01,  1.30680060e+00, -5.54188108e+00,\n",
       "        1.06211948e+01, -2.73097754e+00, -1.03581190e+01, -2.26550503e+01,\n",
       "       -1.29465094e+01, -2.31160183e+01,  2.00000003e-01,  2.28550491e+01,\n",
       "        1.13454571e+01, -1.17107487e+00,  4.26711464e+00, -2.30046058e+00,\n",
       "       -2.07104301e+00, -1.03523121e+01,  3.89655375e+00, -9.43304253e+00,\n",
       "       -5.81720734e+00, -1.52577696e+01,  1.65257126e-01, -4.92328215e+00,\n",
       "        6.83304262e+00, -1.30116022e+00, -6.27671766e+00,  1.57779455e+01,\n",
       "        2.54297471e+00,  7.07154036e+00,  2.61155167e+01,  9.34463787e+00,\n",
       "        1.42100006e+02,  1.39560150e+02,  1.42100006e+02,  1.38739517e+02,\n",
       "        1.39560150e+02,  1.38739517e+02,  1.39560150e+02,  2.13917923e+01,\n",
       "        2.15145454e+01,  2.13527489e+01,  2.09852562e+01,  2.05783176e+01,\n",
       "        2.13917923e+01,  2.13527489e+01,  2.05783176e+01,  1.48145142e+01,\n",
       "        2.09746780e+01,  2.20000000e+01,  1.32000008e+01,  1.48145142e+01,\n",
       "        1.74337677e+02,  1.43221344e+02,  1.02988274e+02,  1.53777985e+02,\n",
       "        1.22543167e+02,  6.48056870e+01,  1.39248901e+02,  4.62832794e+02,\n",
       "        2.88675415e+02,  7.23109680e+02,  3.62392807e+01,  2.07978241e+02,\n",
       "        3.40857513e+02,  8.17948456e+01,  3.39802429e+02,  1.07593225e+03,\n",
       "        3.63175873e+02,  6.34389221e+02,  1.14229114e+03,  9.62279724e+02,\n",
       "        1.81409553e-01,  1.43257767e-01,  1.07337400e-01,  1.53100073e-01,\n",
       "        1.22034170e-01,  6.12906516e-02,  1.39248908e-01,  6.08990490e-01,\n",
       "        6.41500950e-01,  9.51460123e-01,  9.53665301e-02,  5.47311187e-01,\n",
       "        4.48496729e-01,  2.15249598e-01,  4.47108448e-01,  2.93705076e-01,\n",
       "        1.42942235e-01,  2.59601504e-01,  4.89553332e-01,  3.36797923e-01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.observation for s in data_60.steps][0][:324-96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/grid2op/MakeEnv/Make.py:317: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "env = grid2op.make(\"rte_case14_realistic\",test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space = env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEFORE_COMPAT_VERSION',\n",
       " 'GEN_COL',\n",
       " 'LEX_COL',\n",
       " 'LOA_COL',\n",
       " 'LOR_COL',\n",
       " 'STORAGE_COL',\n",
       " 'SUB_COL',\n",
       " '_INIT_GRID_CLS',\n",
       " '_PATH_ENV',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_assign_attr_from_name',\n",
       " '_aux_pos_big_topo',\n",
       " '_backend_obs',\n",
       " '_build_cls_from_import',\n",
       " '_change_parameters',\n",
       " '_check_names',\n",
       " '_check_sub_id',\n",
       " '_check_sub_pos',\n",
       " '_check_topo_vect',\n",
       " '_check_validity_alarm_data',\n",
       " '_check_validity_dispathcing_data',\n",
       " '_check_validity_shunt_data',\n",
       " '_check_validity_storage_data',\n",
       " '_clear_class_attribute',\n",
       " '_compute_pos_big_topo',\n",
       " '_compute_pos_big_topo_cls',\n",
       " '_compute_sub_elements',\n",
       " '_compute_sub_pos',\n",
       " '_convert_to_json',\n",
       " '_custom_deepcopy_for_copy',\n",
       " '_empty_obs',\n",
       " '_fill_names',\n",
       " '_format_bool_vect_to_cls_str',\n",
       " '_format_float_vect_to_cls_str',\n",
       " '_format_int_vect_to_cls_str',\n",
       " '_get_array_from_attr_name',\n",
       " '_get_full_cls_str',\n",
       " '_init_class_attr',\n",
       " '_init_subtype',\n",
       " '_li_attr_disp',\n",
       " '_make_cls_dict',\n",
       " '_make_cls_dict_extended',\n",
       " '_post_process_from_vect',\n",
       " '_raise_error_attr_list_none',\n",
       " '_reward_func',\n",
       " '_simulate_parameters',\n",
       " '_template_obj',\n",
       " '_to_extract_vect',\n",
       " '_topo_vect_to_sub',\n",
       " '_type_attr_disp',\n",
       " '_update_env_time',\n",
       " '_update_value_set',\n",
       " '_vectorized',\n",
       " 'action_helper_env',\n",
       " 'alarms_area_lines',\n",
       " 'alarms_area_names',\n",
       " 'alarms_lines_area',\n",
       " 'assert_grid_correct_cls',\n",
       " 'attach_layout',\n",
       " 'attr_list_json',\n",
       " 'attr_list_set',\n",
       " 'attr_list_vect',\n",
       " 'attr_nan_list_set',\n",
       " 'change_other_rewards',\n",
       " 'change_reward',\n",
       " 'check_space_legit',\n",
       " 'cls_to_dict',\n",
       " 'copy',\n",
       " 'deactivate_storage',\n",
       " 'dim_alarms',\n",
       " 'dim_topo',\n",
       " 'dtype',\n",
       " 'env_name',\n",
       " 'extract_from_vect',\n",
       " 'from_dict',\n",
       " 'from_json',\n",
       " 'from_vect',\n",
       " 'gen_cost_per_MW',\n",
       " 'gen_max_ramp_down',\n",
       " 'gen_max_ramp_up',\n",
       " 'gen_min_downtime',\n",
       " 'gen_min_uptime',\n",
       " 'gen_pmax',\n",
       " 'gen_pmin',\n",
       " 'gen_pos_topo_vect',\n",
       " 'gen_redispatchable',\n",
       " 'gen_renewable',\n",
       " 'gen_shutdown_cost',\n",
       " 'gen_startup_cost',\n",
       " 'gen_to_sub_pos',\n",
       " 'gen_to_subid',\n",
       " 'gen_type',\n",
       " 'get_empty_observation',\n",
       " 'get_generators_id',\n",
       " 'get_indx_extract',\n",
       " 'get_lines_id',\n",
       " 'get_loads_id',\n",
       " 'get_obj_connect_to',\n",
       " 'get_obj_substations',\n",
       " 'get_storages_id',\n",
       " 'global_vars',\n",
       " 'glop_version',\n",
       " 'grid_layout',\n",
       " 'grid_objects_types',\n",
       " 'init_grid',\n",
       " 'init_grid_from_dict_for_pickle',\n",
       " 'line_ex_pos_topo_vect',\n",
       " 'line_ex_to_sub_pos',\n",
       " 'line_ex_to_subid',\n",
       " 'line_or_pos_topo_vect',\n",
       " 'line_or_to_sub_pos',\n",
       " 'line_or_to_subid',\n",
       " 'load_pos_topo_vect',\n",
       " 'load_to_sub_pos',\n",
       " 'load_to_subid',\n",
       " 'n',\n",
       " 'n_gen',\n",
       " 'n_line',\n",
       " 'n_load',\n",
       " 'n_shunt',\n",
       " 'n_storage',\n",
       " 'n_sub',\n",
       " 'name_gen',\n",
       " 'name_line',\n",
       " 'name_load',\n",
       " 'name_shunt',\n",
       " 'name_storage',\n",
       " 'name_sub',\n",
       " 'obs_env',\n",
       " 'observationClass',\n",
       " 'process_grid2op_compat',\n",
       " 'redispatching_unit_commitment_availble',\n",
       " 'reset',\n",
       " 'reset_space',\n",
       " 'reward_helper',\n",
       " 'same_grid_class',\n",
       " 'seed',\n",
       " 'seed_used',\n",
       " 'set_env_name',\n",
       " 'set_no_storage',\n",
       " 'shape',\n",
       " 'shunt_to_subid',\n",
       " 'shunts_data_available',\n",
       " 'size',\n",
       " 'size_obs',\n",
       " 'space_prng',\n",
       " 'storage_Emax',\n",
       " 'storage_Emin',\n",
       " 'storage_charging_efficiency',\n",
       " 'storage_discharging_efficiency',\n",
       " 'storage_loss',\n",
       " 'storage_marginal_cost',\n",
       " 'storage_max_p_absorb',\n",
       " 'storage_max_p_prod',\n",
       " 'storage_pos_topo_vect',\n",
       " 'storage_to_sub_pos',\n",
       " 'storage_to_subid',\n",
       " 'storage_type',\n",
       " 'sub_info',\n",
       " 'subtype',\n",
       " 'tell_dim_alarm',\n",
       " 'to_json',\n",
       " 'to_vect',\n",
       " 'with_forecast']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.44000015e+01,  7.45999985e+01,  3.49000015e+01,  2.00000003e-01,\n",
       "        7.69650574e+01,  2.06861515e+01,  7.50823746e+01,  4.76640549e+01,\n",
       "        2.61155167e+01, -1.72150040e+01,  1.42100006e+02,  1.42100006e+02,\n",
       "        2.20000000e+01,  1.32000008e+01,  1.42100006e+02,  2.27999992e+01,\n",
       "        8.78000031e+01,  4.62000008e+01,  7.59999990e+00,  1.18999996e+01,\n",
       "        3.15000000e+01,  9.19999981e+00,  3.70000005e+00,  6.30000019e+00,\n",
       "        1.41000004e+01,  1.58999996e+01,  1.58999996e+01,  6.14000015e+01,\n",
       "        3.20999985e+01,  5.19999981e+00,  8.50000000e+00,  2.22000008e+01,\n",
       "        6.40000010e+00,  2.59999990e+00,  4.50000000e+00,  9.80000019e+00,\n",
       "        1.11999998e+01,  1.42100006e+02,  1.42100006e+02,  1.38739517e+02,\n",
       "        1.39560150e+02,  2.20000000e+01,  2.09746780e+01,  2.09852562e+01,\n",
       "        2.13917923e+01,  2.15145454e+01,  2.13527489e+01,  2.05783176e+01,\n",
       "        4.17312355e+01,  3.52338219e+01,  2.52821007e+01,  3.76640167e+01,\n",
       "        3.00355530e+01,  1.17861767e+01, -3.32857895e+01,  1.45653477e+01,\n",
       "        9.17162418e+00,  2.23790493e+01, -1.30629933e+00,  5.60785866e+00,\n",
       "       -1.05068007e+01,  2.74871397e+00,  1.05949574e+01,  2.26550503e+01,\n",
       "        1.29465094e+01,  2.31160183e+01, -2.00000003e-01, -2.28550491e+01,\n",
       "       -1.58765821e+01, -1.33842230e+00, -7.66452456e+00,  1.15318716e+00,\n",
       "       -4.79682907e-02,  9.41525745e+00, -3.43005729e+00,  9.94432831e+00,\n",
       "        6.07301807e+00,  1.60751686e+01, -1.63925454e-01,  5.06362581e+00,\n",
       "       -6.56525707e+00,  1.31720757e+00,  6.75892973e+00, -1.43544941e+01,\n",
       "       -1.66267478e+00, -5.85443544e+00, -2.51225834e+01, -8.74565887e+00,\n",
       "        1.42100006e+02,  1.42100006e+02,  1.42100006e+02,  1.42100006e+02,\n",
       "        1.42100006e+02,  1.42100006e+02,  1.38739517e+02,  2.20000000e+01,\n",
       "        2.20000000e+01,  2.20000000e+01,  2.09746780e+01,  2.09746780e+01,\n",
       "        2.09852562e+01,  2.15145454e+01,  2.13527489e+01,  1.38739517e+02,\n",
       "        1.38739517e+02,  1.39560150e+02,  1.48145142e+01,  2.09746780e+01,\n",
       "        1.81409546e+02,  1.43257767e+02,  1.07337402e+02,  1.53100067e+02,\n",
       "        1.22034172e+02,  6.12906532e+01,  1.39248901e+02,  4.62832794e+02,\n",
       "        2.88675415e+02,  7.23109680e+02,  3.62392807e+01,  2.07978241e+02,\n",
       "        3.40857513e+02,  8.17948456e+01,  3.39802429e+02,  1.11607925e+02,\n",
       "        5.43180466e+01,  9.86485748e+01,  9.79106689e+02,  6.73595825e+02,\n",
       "       -4.13816681e+01, -3.46004066e+01, -2.49861813e+01, -3.68817749e+01,\n",
       "       -2.95492935e+01, -1.16339941e+01,  3.34336815e+01, -1.43211946e+01,\n",
       "       -9.04871464e+00, -2.19639797e+01,  1.30680060e+00, -5.54188108e+00,\n",
       "        1.06211948e+01, -2.73097754e+00, -1.03581190e+01, -2.26550503e+01,\n",
       "       -1.29465094e+01, -2.31160183e+01,  2.00000003e-01,  2.28550491e+01,\n",
       "        1.13454571e+01, -1.17107487e+00,  4.26711464e+00, -2.30046058e+00,\n",
       "       -2.07104301e+00, -1.03523121e+01,  3.89655375e+00, -9.43304253e+00,\n",
       "       -5.81720734e+00, -1.52577696e+01,  1.65257126e-01, -4.92328215e+00,\n",
       "        6.83304262e+00, -1.30116022e+00, -6.27671766e+00,  1.57779455e+01,\n",
       "        2.54297471e+00,  7.07154036e+00,  2.61155167e+01,  9.34463787e+00,\n",
       "        1.42100006e+02,  1.39560150e+02,  1.42100006e+02,  1.38739517e+02,\n",
       "        1.39560150e+02,  1.38739517e+02,  1.39560150e+02,  2.13917923e+01,\n",
       "        2.15145454e+01,  2.13527489e+01,  2.09852562e+01,  2.05783176e+01,\n",
       "        2.13917923e+01,  2.13527489e+01,  2.05783176e+01,  1.48145142e+01,\n",
       "        2.09746780e+01,  2.20000000e+01,  1.32000008e+01,  1.48145142e+01,\n",
       "        1.74337677e+02,  1.43221344e+02,  1.02988274e+02,  1.53777985e+02,\n",
       "        1.22543167e+02,  6.48056870e+01,  1.39248901e+02,  4.62832794e+02,\n",
       "        2.88675415e+02,  7.23109680e+02,  3.62392807e+01,  2.07978241e+02,\n",
       "        3.40857513e+02,  8.17948456e+01,  3.39802429e+02,  1.07593225e+03,\n",
       "        3.63175873e+02,  6.34389221e+02,  1.14229114e+03,  9.62279724e+02,\n",
       "        1.81409553e-01,  1.43257767e-01,  1.07337400e-01,  1.53100073e-01,\n",
       "        1.22034170e-01,  6.12906516e-02,  1.39248908e-01,  6.08990490e-01,\n",
       "        6.41500950e-01,  9.51460123e-01,  9.53665301e-02,  5.47311187e-01,\n",
       "        4.48496729e-01,  2.15249598e-01,  4.47108448e-01,  2.93705076e-01,\n",
       "        1.42942235e-01,  2.59601504e-01,  4.89553332e-01,  3.36797923e-01,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.observation for s in data_60.steps][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncorrectNumberOfElements",
     "evalue": "Grid2OpException EnvError IncorrectNumberOfElements \"Incorrect number of elements found while load a GridObjects from a vector. Found 324 elements instead of 437\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncorrectNumberOfElements\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a9b3b6f00518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/grid2op/Space/SerializableSpace.py\u001b[0m in \u001b[0;36mfrom_vect\u001b[0;34m(self, obj_as_vect, check_legit)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \"\"\"\n\u001b[1;32m    278\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_template_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_as_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_legit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_legit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/grid2op/Observation/BaseObservation.py\u001b[0m in \u001b[0;36mfrom_vect\u001b[0;34m(self, vect, check_legit)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         \u001b[0;31m# and ensure everything is reloaded properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_legit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_legit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/grid2op/Space/GridObjects.py\u001b[0m in \u001b[0;36mfrom_vect\u001b[0;34m(self, vect, check_legit)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \"\"\"\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             raise IncorrectNumberOfElements(\"Incorrect number of elements found while load a GridObjects \"\n\u001b[0m\u001b[1;32m    990\u001b[0m                                             \u001b[0;34m\"from a vector. Found {} elements instead of {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                                             \"\".format(vect.shape[0], self.size()))\n",
      "\u001b[0;31mIncorrectNumberOfElements\u001b[0m: Grid2OpException EnvError IncorrectNumberOfElements \"Incorrect number of elements found while load a GridObjects from a vector. Found 324 elements instead of 437\""
     ]
    }
   ],
   "source": [
    "observation_space.from_vect([s.observation for s in data_60.steps][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s.observation for s in data_60.steps][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
