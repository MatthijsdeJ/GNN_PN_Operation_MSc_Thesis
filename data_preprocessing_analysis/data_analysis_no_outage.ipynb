{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Imports from this projects\n",
    "import auxiliary.util as util\n",
    "util.set_wd_to_package_root()\n",
    "import auxiliary.config as config\n",
    "import auxiliary.grid2op_util as g2o_util\n",
    "from auxiliary.generate_action_space import action_identificator\n",
    "import data_preprocessing_analysis.imitation_data_preprocessing as idp\n",
    "\n",
    "#Mathematics\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Collections\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "#File manipulation\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd #Data manipulation & analsysis\n",
    "import grid2op #Grid simulation\n",
    "import matplotlib.pyplot as plt #Plotting\n",
    "import ipdb #Debugger\n",
    "import re #Regular expressions\n",
    "import functools #Higher-order functions\n",
    "from tqdm import tqdm #Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = config['paths']['processed_tutor_imitation']\n",
    "con_matrix_path = config['paths']['con_matrix_cache']\n",
    "fstats_path = config['paths']['feature_statistics']\n",
    "\n",
    "chronics_excluded = [310, 446, 777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['paths']['processed_tutor_imitation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block defines several data aggregates, such as counters. The processed data is loaded a file at a time, gradually filling the data aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub = 14\n",
    "\n",
    "#Inbstantiate the counter objects\n",
    "counters = {\n",
    "    'n_datapoints':0,\n",
    "    'n_days_completed':0,\n",
    "    'n_chronics':0,\n",
    "    'set_hash': collections.Counter(),\n",
    "    'res_hash': collections.Counter(),\n",
    "    'tv_hash': collections.Counter(),\n",
    "    'sub_changed': (n_sub+1) * [0],\n",
    "    'changed_subs_n': n_sub * [0],\n",
    "    'sub_info': []\n",
    "}\n",
    "        \n",
    "# To count numpy arrays, we index their counters with hashes, stored in hash dictionaries:\n",
    "hash_to_act = {} #'Set'-action hashes\n",
    "hash_to_tv = {} #Topology vector hashes\n",
    "hash_to_res = {} #Resulting (i.e. post-action) topology vector hashes\n",
    "\n",
    "\n",
    "for f in tqdm(list(Path(processed_data_path).rglob('*.json'))):\n",
    "    with open(f, 'r') as file:\n",
    "            dps = json.loads(file.read())\n",
    "    \n",
    "    counters['n_chronics']+=1\n",
    "    counters['n_days_completed']+=dps[0]['dayscomp']\n",
    "    for dp in dps:\n",
    "        #Increase n. datapoints\n",
    "        counters['n_datapoints']+=1\n",
    "        \n",
    "        #Count set_topo_vect\n",
    "        hsh_set = util.hash_nparray(np.array(dp['set_topo_vect']))\n",
    "        if hsh_set not in hash_to_act:\n",
    "            hash_to_act[hsh_set] = dp['set_topo_vect']\n",
    "        counters['set_hash'][hsh_set]+=1\n",
    "        \n",
    "        #Count res_topo_vect\n",
    "        hsh_res = util.hash_nparray(np.array(dp['res_topo_vect']))\n",
    "        if hsh_res not in hash_to_res:\n",
    "            hash_to_res[hsh_res] = dp['res_topo_vect']\n",
    "        counters['res_hash'][hsh_res]+=1\n",
    "        \n",
    "        #Count topo_vect\n",
    "        hsh_tv = util.hash_nparray(np.array(dp['topo_vect']))\n",
    "        if hsh_tv not in hash_to_tv:\n",
    "            hash_to_tv[hsh_tv] = dp['topo_vect']\n",
    "        counters['tv_hash'][hsh_tv]+=1\n",
    "        \n",
    "        #Count substations affected\n",
    "        action_per_sub = g2o_util.tv_groupby_subst(dp['set_topo_vect'],dp['sub_info'])\n",
    "        try:\n",
    "            changed_subs_id = [np.any(a) for i,a in enumerate(action_per_sub)].index(True)\n",
    "            counters['sub_changed'][changed_subs_id] += 1\n",
    "        except:\n",
    "            counters['sub_changed'][-1] += 1\n",
    "\n",
    "        #Count topological depth of resulting topologies\n",
    "        #ASSUMPTION: reference topology is the topology where all objects are connected to bus 1\n",
    "        res_per_sub = g2o_util.tv_groupby_subst(dp['res_topo_vect'],dp['sub_info'])\n",
    "        changed_subs_n = sum([2 in res for i,res in enumerate(res_per_sub)])\n",
    "        counters['changed_subs_n'][changed_subs_n] += 1\n",
    "        \n",
    "        #Set sub info\n",
    "        counters['sub_info'] = dp['sub_info']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of chronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chronics: {counters['n_chronics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Days completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Days completed: {counters['n_days_completed']}\")\n",
    "print(f\"Fraction days completed: {counters['n_days_completed']/(28*counters['n_chronics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of actions/datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the term 'action' here instead of 'datapoint'\n",
    "print(f\"Actions: {counters['n_datapoints']}\")\n",
    "print(f\"Mean actions per day: {counters['n_datapoints']/(28*counters['n_chronics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Distinct actions: {len(counters['set_hash'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "print(f\"Do-nothing actions: {counters['set_hash'][do_nothing_hash]}\")\n",
    "print(f\"Fraction do-nothing actions: {counters['set_hash'][do_nothing_hash]/counters['n_datapoints']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Action entropy: {entropy(list(counters['set_hash'].values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action distribution plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the actions into the representation:\n",
    "\n",
    "(affected substation index, 'set' configuration of objects at this substation)\n",
    "\n",
    "do-nothing actions are simply transformed into '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting actions into format so that actions at substations\n",
    "standard_sub_info = [3, 6, 4, 6, 5, 6, 3, 2, 5, 3, 3, 3, 4, 3]\n",
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "\n",
    "transformed_act_counter = collections.Counter()\n",
    "\n",
    "# Filling in the counter for the transformed actions\n",
    "for h,c in counters['set_hash'].items():\n",
    "    a = hash_to_act[h]\n",
    "    a_per_substation = g2o_util.tv_groupby_subst(a,standard_sub_info)\n",
    "    \n",
    "    if h == do_nothing_hash:\n",
    "        transformed_act_counter[-1] += c\n",
    "    else:\n",
    "        changed_sub_id = [np.any(a) for a in a_per_substation].index(True)\n",
    "        action = (changed_sub_id,tuple(a_per_substation[changed_sub_id]))\n",
    "        transformed_act_counter[action] += c\n",
    "        \n",
    "#Gettings the keys of this counter\n",
    "keys = list(transformed_act_counter.keys())\n",
    "keys = sorted([t for t in keys if type(t)==tuple])\n",
    "keys = [-1] + keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {\n",
    "    -1:'k',\n",
    "    1:'b',\n",
    "    2:'g',\n",
    "    3:'r',\n",
    "    4:'c',\n",
    "    5:'m',\n",
    "    8:'y',\n",
    "    12:'k',\n",
    "}\n",
    "\n",
    "weight = [transformed_act_counter[i] for i in keys]\n",
    "_, _, patches = plt.hist(range(len(weight)),weights=weight,bins=range(len(weight)+1))\n",
    "\n",
    "\n",
    "#Applying colors\n",
    "for j,t in enumerate(keys[:-1]):\n",
    "    if type(t) == int:\n",
    "        continue\n",
    "    patches[j].set_facecolor(colormap[t[0]])\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "\n",
    "plt.xlabel('Action index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [c for _,c in transformed_act_counter.most_common()]\n",
    "_, _, patches = plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "_ = [patches[i].set_facecolor(colormap[v if v==-1 else v[0]])\n",
    " for i,(v,_) in enumerate(transformed_act_counter.most_common())]\n",
    "plt.xlabel('Action index ordered by frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting TV Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_counter = counters['tv_hash']\n",
    "val, weight = zip(*[(i, v) for i,(k,v) in enumerate(tv_counter.most_common())])\n",
    "plt.hist(val[0:100], weights=weight[0:100],bins=val[0:101])\n",
    "\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting TV Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_counter = counters['res_hash']\n",
    "val, weight = zip(*[(i, v) for i,(k,v) in enumerate(res_counter.most_common())])\n",
    "plt.hist(val[0:100], weights=weight[0:100],bins=val[0:101])\n",
    "\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substations acted on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substations_with_actions = [-1,1,2,3,4,5,8,12]\n",
    "colormap = {\n",
    "    -1:'k',\n",
    "    1:'b',\n",
    "    2:'g',\n",
    "    3:'r',\n",
    "    4:'c',\n",
    "    5:'m',\n",
    "    8:'y',\n",
    "    12:'k',\n",
    "}\n",
    "\n",
    "patches = plt.bar([str(b) for b in substations_with_actions],\n",
    "                   np.array(counters['sub_changed'])[substations_with_actions])\n",
    "_ = [p.set_facecolor(c) for p,c in zip(patches,colormap.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "\n",
    "def mean_index(lst):\n",
    "    return np.sum(np.array([i*v for i,v in enumerate(lst)]))/sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_nonzero = np.count_nonzero(counters['changed_subs_n'])\n",
    "\n",
    "plt.bar([str(n) for n in range(n_sub)][0:nr_nonzero],list(counters['changed_subs_n'])[0:nr_nonzero])\n",
    "plt.title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence data analysis on unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_wd_to_package_root()\n",
    "import auxiliary.config as config\n",
    "config = config.get_config()\n",
    "import grid2op\n",
    "env = grid2op.make('rte_case14_realistic')\n",
    "\n",
    "tutor_data_path = config['paths']['tutor_imitation']\n",
    "ts_in_day = config['rte_case14_realistic']['ts_in_day']\n",
    "\n",
    "line_disabled_to_consider = [-1,0,1,2,3,4,5,6,10,12,13,15,16,19]\n",
    "line_group1 = [-1,0,1,2,3,4,5,6,12]\n",
    "line_group2 = [13,15,16,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idp.get_filepaths(tutor_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_action_counter = Counter()\n",
    "sequence_length_counter = Counter()\n",
    "sequence_counter = Counter()\n",
    "action_ider = action_identificator(env)\n",
    "\n",
    "for fp in tqdm(idp.get_filepaths(tutor_data_path)):\n",
    "    line_disabled, _, _, _ = idp.extract_data_from_filepath(fp.relative_to(tutor_data_path))\n",
    "    \n",
    "    if line_disabled not in line_disabled_to_consider:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Load a single file with raw datapoints\n",
    "    chr_ldis_raw_dps = np.load(fp)\n",
    "    \n",
    "    # Define a sequence data object\n",
    "    sequence = []\n",
    "    subs_already_acted_on_in_sequence = []\n",
    "    # Loop over datapoints\n",
    "    for action_idx, timestep in chr_ldis_raw_dps[:,(0,4)]:\n",
    "\n",
    "        \n",
    "        action_idx = int(action_idx)\n",
    "        timestep  = int(timestep)\n",
    "        set_action = action_ider.get_set_topo_vect(action_idx)\n",
    "        action_subid = util.argmax_f(g2o_util.tv_groupby_subst(set_action,\n",
    "                                                               [3, 6, 4, 6, 5, 6, 3, 2, 5, 3, 3, 3, 4, 3]),\n",
    "                                     sum)\n",
    "        \n",
    "        unitary_action_counter[action_idx] += 1\n",
    "        \n",
    "        # If, terminiation condition for a sequence: \n",
    "        #     The action is a do-nothing action OR \n",
    "        #     two timesteps are not consecutive OR\n",
    "        #     two timesteps are not in the same day\n",
    "        # then save the sequence (if it is not empty), and reset the sequence\n",
    "        if (action_idx == -1 or\n",
    "           (sequence and (sequence[-1][1] != timestep-1 or\n",
    "                          g2o_util.ts_to_day(sequence[-1][1], ts_in_day) != g2o_util.ts_to_day(timestep, ts_in_day)) or\n",
    "           action_subid in subs_already_acted_on_in_sequence)):\n",
    "            \n",
    "            # Save the sequence if not empty\n",
    "            if sequence:\n",
    "                sequence_length_counter[len(sequence)] += 1\n",
    "                \n",
    "            \n",
    "            if len(sequence)>-1:\n",
    "                sequence_actions = [a for a,ts in sequence]\n",
    "                sequence_counter[tuple(sequence_actions)] += 1\n",
    "                \n",
    "            # Reset the sequence\n",
    "            if action_idx == -1:\n",
    "                sequence = []\n",
    "                subs_already_acted_on_in_sequence = []\n",
    "            else:\n",
    "                sequence = [(action_idx, timestep)]\n",
    "                subs_already_acted_on_in_sequence = [action_subid]\n",
    "                \n",
    "        # Else, if the action is not do-nothing, add it to the sequence\n",
    "        elif action_idx != -1:\n",
    "            sequence.append((action_idx, timestep))\n",
    "            subs_already_acted_on_in_sequence.append(action_subid)\n",
    "        else:\n",
    "            assert False, 'Either of above conditions should be true: this statement should not be reached'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length_counter.keys())\n",
    "rnge = np.arange(1,max_sequence_length)\n",
    "plt.bar([str(i) for i in rnge], \n",
    "        [sequence_length_counter[i] for i in rnge])\n",
    "plt.title(\"Sequence length distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,sequence_length_counter[i]/sequence_length_counter[i-1]) for i in np.arange(2,max_sequence_length) \n",
    " if sequence_length_counter[i-1] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting sequence distributions for sequences larger than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_counter = Counter({x: count for x, count in sequence_counter.items() if len(x)>1})\n",
    "weight = [n for _,n in filtered_sequence_counter.most_common()][0:100]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)))\n",
    "plt.title(\"Distribution of sequence frequency for frequencies longer than one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seq_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting sequences including permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_counter = Counter({x: count for x, count in sequence_counter.items() if len(x)>1})\n",
    "\n",
    "set_seq_counter = Counter()\n",
    "for seq,n in filtered_sequence_counter.most_common():\n",
    "    set_seq_counter[tuple(set(seq))] += n\n",
    "weight = [n for _,n in set_seq_counter.most_common()][0:60]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)))\n",
    "plt.title(\"Distribution of sequence frequency for frequencies longer than one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting sequences including permutations of all sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_counter = Counter({x: count for x, count in sequence_counter.items() if len(x)>0})\n",
    "\n",
    "set_seq_counter = Counter()\n",
    "for seq,n in filtered_sequence_counter.most_common():\n",
    "    set_seq_counter[tuple(set(seq))] += n\n",
    "weight = [n for _,n in set_seq_counter.most_common()][0:60]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)))\n",
    "plt.title(\"Distribution of sequence frequency for frequencies longer than one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent action analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequent_actions = [a for a,c in unitary_action_counter.most_common() if c>1000]\n",
    "frequent_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq_action_by_sequence_length_counter = Counter()\n",
    "for seq, n in sequence_counter.items():\n",
    "    for act in seq:\n",
    "        n_freq_action_by_sequence_length_counter[len(seq)] += n if act in frequent_actions else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.arange(2,6)\n",
    "perc_freq_act_per_seq_len = np.array([n_freq_action_by_sequence_length_counter[i] for i in rng])/np.array([sequence_length_counter[i]*i for i in rng])\n",
    "plt.bar([str(i) for i in rng],perc_freq_act_per_seq_len)\n",
    "plt.title('Percentage of frequent actions (>1000) in sequences per sequence length')\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Percentage of frequent actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.arange(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
