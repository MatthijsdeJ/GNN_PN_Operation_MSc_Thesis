{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Imports from this projects\n",
    "import auxiliary.util as util\n",
    "util.set_wd_to_package_root()\n",
    "import auxiliary.config as config\n",
    "import auxiliary.grid2op_util as g2o_util\n",
    "from auxiliary.generate_action_space import action_identificator\n",
    "import data_preprocessing_analysis.imitation_data_preprocessing as idp\n",
    "\n",
    "#Mathematics\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Collections\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "#File manipulation\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd #Data manipulation & analsysis\n",
    "import grid2op #Grid simulation\n",
    "import matplotlib.pyplot as plt #Plotting\n",
    "import ipdb #Debugger\n",
    "import re #Regular expressions\n",
    "import functools #Higher-order functions\n",
    "from tqdm import tqdm #Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_wd_to_package_root()\n",
    "import auxiliary.config as config\n",
    "config = config.get_config()\n",
    "import grid2op\n",
    "env = grid2op.make('rte_case14_realistic')\n",
    "\n",
    "tutor_data_path = config['paths']['tutor_imitation']\n",
    "ts_in_day = config['rte_case14_realistic']['ts_in_day']\n",
    "\n",
    "line_disabled_to_consider = [-1,0,1,2,3,4,5,6,10,12,13,15,16,19]\n",
    "line_group1 = [-1,0,1,2,3,4,5,6,12]\n",
    "line_group2 = [13,15,16,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idp.get_filepaths(tutor_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters\n",
    "action_counter = Counter()\n",
    "sequence_counter = Counter()\n",
    "sequence_length_counter = Counter()\n",
    "\n",
    "#Define action identifier that links action indexes to actions\n",
    "action_ider = action_identificator(env)\n",
    "\n",
    "#Loop over filepaths\n",
    "for filepath in tqdm(idp.get_filepaths(tutor_data_path)):\n",
    "    \n",
    "    #Ignore certain outage-topologies\n",
    "    line_disabled, _, _, _ = idp.extract_data_from_filepath(filepath.relative_to(tutor_data_path))\n",
    "    if line_disabled not in line_disabled_to_consider:\n",
    "        continue\n",
    "    \n",
    "    # Load a single file with raw datapoints\n",
    "    raw_chronic_datapoints = np.load(filepath)\n",
    "    \n",
    "    # Define a sequence data object\n",
    "    sequence = []\n",
    "    subs_in_sequence = []\n",
    "    \n",
    "    # Loop over datapoints\n",
    "    for action_idx, timestep in raw_chronic_datapoints[:,(0,4)]:\n",
    "        \n",
    "        action_idx = int(action_idx)\n",
    "        timestep  = int(timestep)\n",
    "        action = action_ider.get_set_topo_vect(action_idx)\n",
    "        action_subid = util.argmax_f(g2o_util.tv_groupby_subst(action,\n",
    "                                                               [3, 6, 4, 6, 5, 6, 3, 2, 5, 3, 3, 3, 4, 3]),\n",
    "                                     sum)\n",
    "        \n",
    "        action_counter[action_idx] += 1\n",
    "        \n",
    "        reset_sequence = False\n",
    "        if action_idx == -1:\n",
    "            reset_sequence = True\n",
    "        elif sequence:\n",
    "            if (sequence[-1][1] != timestep-1 or\n",
    "                g2o_util.ts_to_day(sequence[-1][1], ts_in_day) != g2o_util.ts_to_day(timestep, ts_in_day) or\n",
    "                action_subid in subs_in_sequence):\n",
    "                reset_sequence = True\n",
    "\n",
    "            \n",
    "        if reset_sequence and sequence:\n",
    "            #Save sequence\n",
    "            sequence_actions = [a for a,ts in sequence]\n",
    "            sequence_counter[tuple(sequence_actions)] += 1\n",
    "            sequence_length_counter[len(sequence)] += 1\n",
    "            #Reset sequence\n",
    "            sequence = []\n",
    "            subs_in_sequence = []\n",
    "            \n",
    "        if action_idx != -1:\n",
    "            sequence.append((action_idx, timestep))\n",
    "            subs_in_sequence.append(action_subid)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "#         # If, terminiation condition for a sequence: \n",
    "#         #     The action is a do-nothing action OR \n",
    "#         #     two timesteps are not consecutive OR\n",
    "#         #     two timesteps are not in the same day OR\n",
    "#         #     the acted-on substatation is already in the sequence\n",
    "#         # then save the sequence (if it is not empty), and reset the sequence\n",
    "#         if (action_idx == -1 or\n",
    "#            (sequence and (sequence[-1][1] != timestep-1 or\n",
    "#                           g2o_util.ts_to_day(sequence[-1][1], ts_in_day) != g2o_util.ts_to_day(timestep, ts_in_day)) or\n",
    "#            action_subid in subs_already_acted_on_in_sequence)):\n",
    "            \n",
    "#             # Save the sequence if not empty\n",
    "#             if sequence:\n",
    "#                 sequence_length_counter[len(sequence)] += 1\n",
    "                \n",
    "            \n",
    "#             if len(sequence)>-1:\n",
    "#                 sequence_actions = [a for a,ts in sequence]\n",
    "#                 sequence_counter[tuple(sequence_actions)] += 1\n",
    "                \n",
    "#             # Reset the sequence\n",
    "#             if action_idx == -1:\n",
    "#                 sequence = []\n",
    "#                 subs_already_acted_on_in_sequence = []\n",
    "#             else:\n",
    "#                 sequence = [(action_idx, timestep)]\n",
    "#                 subs_already_acted_on_in_sequence = [action_subid]\n",
    "                \n",
    "#         # If the sequence is not terminated, if the action is not do-nothing, add it to the sequence\n",
    "#         elif action_idx != -1:\n",
    "#             sequence.append((action_idx, timestep))\n",
    "#             subs_already_acted_on_in_sequence.append(action_subid)\n",
    "#         else:\n",
    "#             assert False, 'Either of above conditions should be true: this statement should not be reached'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length_counter.keys())\n",
    "rnge = np.arange(1,max_sequence_length+1)\n",
    "plt.bar([str(i) for i in rnge], \n",
    "        [sequence_length_counter[i] for i in rnge])\n",
    "plt.title(\"Sequence length distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [n for _,n in sequence_counter.most_common()][0:100]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "plt.title(\"Distribution of sequence frequency for frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting sequence distributions for sequences larger than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_counter = Counter({x: count for x, count in sequence_counter.items() if len(x)>1})\n",
    "weight = [n for _,n in filtered_sequence_counter.most_common()][0:100]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "plt.title(\"Distribution of sequence frequency for sequences longer than one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring action ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seq_counter = Counter()\n",
    "for seq,n in sequence_counter.most_common():\n",
    "    set_seq_counter[tuple(set(seq))] += n\n",
    "weight = [n for _,n in set_seq_counter.most_common()][0:100]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "plt.title(\"Distribution of unordered sequence frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_counter = Counter({x: count for x, count in sequence_counter.items() if len(x)>1})\n",
    "\n",
    "set_seq_counter = Counter()\n",
    "for seq,n in filtered_sequence_counter.most_common():\n",
    "    set_seq_counter[tuple(set(seq))] += n\n",
    "weight = [n for _,n in set_seq_counter.most_common()][0:100]\n",
    "plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "plt.title(\"Distribution of unorderer sequence frequency for sequences longer than one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent action analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequent_actions = [a for a,c in action_counter.most_common() if c>1000]\n",
    "frequent_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq_action_by_sequence_length_counter = Counter()\n",
    "for seq, n in sequence_counter.items():\n",
    "    for act in seq:\n",
    "        n_freq_action_by_sequence_length_counter[len(seq)] += n if act in frequent_actions else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.arange(2,6)\n",
    "perc_freq_act_per_seq_len = np.array([n_freq_action_by_sequence_length_counter[i] for i in rng])/np.array([sequence_length_counter[i]*i for i in rng])\n",
    "plt.bar([str(i) for i in rng],perc_freq_act_per_seq_len)\n",
    "plt.title('Percentage of frequent actions (>1000) in sequences per sequence length')\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Percentage of frequent actions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
