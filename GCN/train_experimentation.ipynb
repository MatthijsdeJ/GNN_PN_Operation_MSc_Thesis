{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import random\n",
    "import util\n",
    "from typing import Union, List, Tuple, Optional\n",
    "\n",
    "from torch_geometric.data import Dataset\n",
    "#import imitation_data_loading\n",
    "#from tutor_data_loading import preprocess_observation, action_identificator, Episode, EpisodeStep, EpisodeSet, StepSet\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import wandb\n",
    "import training as trn\n",
    "from model import GCN\n",
    "from dataloader import TutorDataLoader\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.load_config()\n",
    "processed_data_path = 'data/nooutage_processed_tutor_data/' #config['paths']['processed_tutor_imitation']\n",
    "matrix_cache_path = config['paths']['con_matrix_cache']\n",
    "feature_statistics_path = config['paths']['feature_statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import TutorDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo seperate static (line capacities, 'standard' voltage) and dynamic attributes\n",
    "#compare weights or/ex layers (sign?)\n",
    "#feature: number of connected nodes?\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = util.load_config()['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'test_hetero_labelsmth',\n",
       " 'model_tags': ['test'],\n",
       " 'train_log_freq': 2000,\n",
       " 'val_log_freq': 60,\n",
       " 'n_epoch': 100,\n",
       " 'lr': 0.003,\n",
       " 'network_type': 'heterogenous',\n",
       " 'N_GNN_layers': 8,\n",
       " 'N_node_hidden': 32,\n",
       " 'LReLu_neg_slope': 0.1,\n",
       " 'batch_size': 64,\n",
       " 'label_smoothing_alpha': 0.2,\n",
       " 'aggr': 'add',\n",
       " 'N_f_gen': 3,\n",
       " 'N_f_load': 3,\n",
       " 'N_f_endpoint': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/mattholomew/msc_thesis_gnn_power/runs/2vf4qg5d?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7f29644d2280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8700/2079400 [4:37:55<1102:28:36,  1.92s/it]  \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/matthijs/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-c5197ac40f48>\", line 71, in <module>\n",
      "    P = model(X_gen, X_load, X_or, X_ex, E, object_ptv).reshape((-1))\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1071, in _call_impl\n",
      "    result = forward_call(*input, **kwargs)\n",
      "  File \"/home/matthijs/Projects/University/Masters_thesis/Software/GNN_PN_Operation_MSc_Thesis/model.py\", line 162, in forward\n",
      "    x=l(x, edge_index)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1071, in _call_impl\n",
      "    result = forward_call(*input, **kwargs)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/hetero_conv.py\", line 92, in forward\n",
      "    out = conv(x=x_dict[src], edge_index=edge_index, **kwargs)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py\", line 71, in forward\n",
      "    out = self.propagate(edge_index, x=x, size=size)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\", line 265, in propagate\n",
      "    for hook in self._message_forward_pre_hooks.values():\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthijs/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthijs/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/matthijs/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/matthijs/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/inspect.py\", line 721, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/matthijs/Software/anaconda3/lib/python3.8/posixpath.py\", line 360, in normpath\n",
      "    if (comp != dotdot or (not initial_slashes and not new_comps) or\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c5197ac40f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;31m#Pass through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_ptv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/University/Masters_thesis/Software/GNN_PN_Operation_MSc_Thesis/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_gen, x_load, x_or, x_ex, edge_index, object_ptv)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGNN_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'homogenous'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/hetero_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "estimated_train_size = int(0.8*25993)\n",
    "label_smth_alpha = training_config['label_smoothing_alpha']\n",
    "\n",
    "\n",
    "with tqdm(total=n_epoch*estimated_train_size) as pbar:\n",
    "    model.zero_grad()\n",
    "    step=0\n",
    "    for e in range(n_epoch):\n",
    "        for datapoint in train_dl:\n",
    "            \n",
    "            #Get information from datapoint\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.266310691833496"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_W_sb_neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2379, -0.4808, -0.3585],\n",
       "        [-0.1288,  0.4274, -0.5205],\n",
       "        [ 0.4741,  0.3835, -0.3093],\n",
       "        [-0.0464,  0.4933, -0.1828],\n",
       "        [-0.4257,  0.4076,  0.1399],\n",
       "        [-0.1824, -0.3836,  0.2479],\n",
       "        [ 0.5565, -0.1509, -0.4988],\n",
       "        [-0.5888,  0.3907,  0.0116],\n",
       "        [ 0.1203, -0.5534, -0.3752],\n",
       "        [ 0.3697,  0.4229,  0.0760],\n",
       "        [-0.1694,  0.0545, -0.4772],\n",
       "        [-0.3625,  0.3387,  0.3474],\n",
       "        [-0.5713, -0.4578,  0.3157],\n",
       "        [-0.3539,  0.3325, -0.2539],\n",
       "        [-0.4976, -0.4762,  0.0238],\n",
       "        [ 0.2982, -0.5198,  0.4801],\n",
       "        [-0.5224, -0.4563, -0.1816],\n",
       "        [-0.2758, -0.3707,  0.1586],\n",
       "        [-0.0316,  0.1728,  0.5759],\n",
       "        [ 0.5199,  0.0441, -0.4308],\n",
       "        [ 0.2431, -0.1268,  0.4708],\n",
       "        [ 0.3925,  0.2435, -0.4217],\n",
       "        [ 0.5223,  0.3322,  0.4148],\n",
       "        [-0.2115,  0.0356,  0.4968],\n",
       "        [-0.2238, -0.5631,  0.3549],\n",
       "        [-0.1094,  0.1531, -0.1201],\n",
       "        [-0.4127,  0.4636, -0.3425],\n",
       "        [-0.2937, -0.3759,  0.0340],\n",
       "        [ 0.4448, -0.0140, -0.3124],\n",
       "        [-0.3734,  0.5213, -0.3208],\n",
       "        [-0.0192,  0.1539, -0.2070],\n",
       "        [-0.5209, -0.3138, -0.1464]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lin_gen_1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.0245, grad_fn=<SumBackward0>)\n",
      "tensor(92.5276, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(abs(model.GNN_layers[6].convs['object__other_busbar__object'].lin_l.weight).sum())\n",
    "print(abs(model.GNN_layers[6].convs['object__same_busbar__object'].lin_r.weight).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([SAGEConv(32, 32), SAGEConv(32, 32), SAGEConv(32, 32)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GNN_layers[6].convs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n",
      "HeteroConv(num_relations=3)\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "for l in model.GNN_layers:\n",
    "    print(l)\n",
    "    if training_config['network_type'] == 'heterogenous':\n",
    "        norm_W_self = abs(l.convs['object__same_busbar__object'].lin_r.weight).sum()\n",
    "        norm_W_neigh = abs(l.convs['object__line__object'].lin_l.weight).sum() + \\\n",
    "                        abs(l.convs['object__same_busbar__object'].lin_l.weight).sum() + \\\n",
    "                        abs(l.convs['object__other_busbar__object'].lin_l.weight).sum()\n",
    "        diffs.append(norm_W_self-norm_W_neigh)\n",
    "    else:\n",
    "        assert False, 'Not developped yet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-179.3683, grad_fn=<SubBackward0>),\n",
       " tensor(-182.3290, grad_fn=<SubBackward0>),\n",
       " tensor(-185.4459, grad_fn=<SubBackward0>),\n",
       " tensor(-190.0928, grad_fn=<SubBackward0>),\n",
       " tensor(-177.2830, grad_fn=<SubBackward0>),\n",
       " tensor(-185.9814, grad_fn=<SubBackward0>),\n",
       " tensor(-189.4445, grad_fn=<SubBackward0>),\n",
       " tensor(-4.3578, grad_fn=<SubBackward0>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4024, -0.2298, -0.5843,  0.2113,  0.0195,  0.5122,  0.0314,  0.0034,\n",
       "         -0.4375, -0.0978,  0.5433, -0.0088,  0.4483,  0.0339, -0.0458, -0.1398,\n",
       "         -0.0524,  0.6143, -0.6052, -0.5855, -0.4438, -0.7107, -0.6309, -0.1906,\n",
       "          0.0552,  0.2951,  0.2318, -0.6349,  0.4756, -0.2710, -0.3650,  0.7686]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GNN_layers[6].convs['object__same_busbar__object'].forward(torch.rand((1,32),device=device),\n",
    "                                                                  torch.tensor([],dtype=torch.long,device=device).reshape(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1600, -0.1250,  0.1153,  0.1432,  0.2888,  0.0582, -0.0455, -0.1784,\n",
       "        -0.2181,  0.1439,  0.0528,  0.1741,  0.3131,  0.3825, -0.1560,  0.0673,\n",
       "        -0.0247,  0.1230,  0.0985,  0.1045, -0.1527, -0.0467, -0.0805, -0.1043,\n",
       "        -0.0272,  0.1199, -0.0111, -0.0191,  0.1485, -0.1440, -0.1403,  0.1936],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GNN_layers[6].convs['object__same_busbar__object'].lin_l.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heterogenous'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config['network_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (activation_f): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  (lin_gen_1): Linear(3, 32, bias=True)\n",
       "  (lin_gen_2): Linear(32, 32, bias=True)\n",
       "  (lin_load_1): Linear(3, 32, bias=True)\n",
       "  (lin_load_2): Linear(32, 32, bias=True)\n",
       "  (lin_or_1): Linear(6, 32, bias=True)\n",
       "  (lin_or_2): Linear(32, 32, bias=True)\n",
       "  (lin_ex_1): Linear(6, 32, bias=True)\n",
       "  (lin_ex_2): Linear(32, 32, bias=True)\n",
       "  (GNN_layers): ModuleList(\n",
       "    (0): HeteroConv(num_relations=3)\n",
       "    (1): HeteroConv(num_relations=3)\n",
       "    (2): HeteroConv(num_relations=3)\n",
       "    (3): HeteroConv(num_relations=3)\n",
       "    (4): HeteroConv(num_relations=3)\n",
       "    (5): HeteroConv(num_relations=3)\n",
       "    (6): HeteroConv(num_relations=3)\n",
       "    (7): HeteroConv(num_relations=3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config = config['training']\n",
    "model = GCN(train_config['hyperparams']['LReLu_neg_slope'],\n",
    "                         train_config['hyperparams']['weight_init_std'],\n",
    "                         train_config['constants']['N_f_gen'],\n",
    "                         train_config['constants']['N_f_load'],\n",
    "                         train_config['constants']['N_f_endpoint'],\n",
    "                         train_config['hyperparams']['N_GNN_layers'],\n",
    "                         train_config['hyperparams']['N_node_hidden'],\n",
    "                         train_config['hyperparams']['aggr'],\n",
    "                         train_config['hyperparams']['network_type'])\n",
    "model.load_state_dict(torch.load('models/earthy-bee-265'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = TutorDataLoader(processed_data_path + '/val', \n",
    "                          matrix_cache_path, \n",
    "                          feature_statistics_path,\n",
    "                          device=device,\n",
    "                          network_type=train_config['hyperparams']['network_type'],\n",
    "                          train=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobs_gen_mean = torch.zeros(3)\n",
    "jacobs_load_mean = torch.zeros(3)\n",
    "jacobs_or_mean = torch.zeros(6)\n",
    "jacobs_ex_mean = torch.zeros(6)\n",
    "jacobs_object_sum = torch.zeros((56,56))\n",
    "\n",
    "Y_sum = torch.zeros(56)\n",
    "for i in range(100):\n",
    "    dp = next(val_dl.__iter__())\n",
    "\n",
    "    #Extract features\n",
    "    X_gen = dp['gen_features']\n",
    "    X_load = dp['load_features']\n",
    "    X_or = dp['or_features']\n",
    "    X_ex = dp['ex_features']   \n",
    "\n",
    "    #Extract the position topology vector, which relates the\n",
    "    #objects ordered by type to their position in the topology vector\n",
    "    object_ptv = dp['object_ptv']\n",
    "\n",
    "    #Extract the edges\n",
    "    E = dp['edges']\n",
    "\n",
    "    #Pass through the model\n",
    "    P = model(X_gen, X_load, X_or, X_ex, E, object_ptv).reshape((-1))\n",
    "\n",
    "    #Extract the label, apply label smoothing\n",
    "    Y = dp['change_topo_vect']\n",
    "    label_smth_alpha = train_config['hyperparams'] \\\n",
    "                                        ['label_smoothing_alpha']\n",
    "    Y_smth =(1-label_smth_alpha)*dp['change_topo_vect'] + \\\n",
    "              label_smth_alpha*0.5*torch.ones_like(Y,device=device)\n",
    "    Y_sum += Y\n",
    "    \n",
    "    #Compute the weights for the loss\n",
    "    non_sub_label_weight = train_config['hyperparams'] \\\n",
    "                                        ['non_sub_label_weight']\n",
    "    Y_sub_mask, Y_sub_idx = trn.get_Y_subchanged(Y,dp['sub_info'])\n",
    "    weights = trn.label_weights(1-Y_sub_mask,non_sub_label_weight)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Compute the loss, update gradients\n",
    "    l = trn.BCELoss_labels_weighted(P,Y_smth,weights)\n",
    "    l.backward()\n",
    "    \n",
    "    #Obtain the jacobian\n",
    "    jacob = torch.autograd.functional.jacobian(func:= lambda xg, xl, xo, xe: \\\n",
    "                                   model(xg,xl,xo,xe,E,object_ptv),\n",
    "                                   inputs=(X_gen, X_load, X_or, X_ex))\n",
    "    \n",
    "    #Aggregate the jacobian to determine the importance of each feature\n",
    "    jacobs_gen_mean += torch.mean(torch.abs(out[0]),axis=(0,1,2))\n",
    "    jacobs_load_mean += torch.mean(torch.abs(out[1]),axis=(0,1,2))\n",
    "    jacobs_or_mean += torch.mean(torch.abs(out[2]),axis=(0,1,2))\n",
    "    jacobs_ex_mean += torch.mean(torch.abs(out[3]),axis=(0,1,2))\n",
    "    #jacobs_or_sum = torch.zeros(6)\n",
    "    #jacobs_ex_sum = torch.zeros(6)\n",
    "    \n",
    "    #Aggregate the jacobian to determine the importance of each object's features to each objects output\n",
    "    jacob_objects = torch.cat([torch.sum(torch.abs(out[0]),axis=(1,3)),\n",
    "        torch.sum(torch.abs(out[1]),axis=(1,3)),\n",
    "        torch.sum(torch.abs(out[2]),axis=(1,3)),\n",
    "        torch.sum(torch.abs(out[3]),axis=(1,3))],axis=1)[:,object_ptv]\n",
    "    jacobs_object_sum += jacob_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "axs[0,0].bar(['p','q','v'],jacobs_gen_mean)\n",
    "axs[0,1].bar(['p','q','v'],jacobs_load_mean)\n",
    "axs[1,0].bar(['p', 'q', 'v', 'a', 'line_rho','line_capacity'],jacobs_or_mean)\n",
    "axs[1,1].bar(['p', 'q', 'v', 'a', 'line_rho','line_capacity'],jacobs_ex_mean)\n",
    "#axs[0,0].bar(['p','q','v'],jacobs_gen_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51daa40dc0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "# gs = gridspec.GridSpec(1,2, height_ratios=[1,1], width_ratios=[1])\n",
    "# print(gs)\n",
    "# f = plt.figure()\n",
    "# ax1 = plt.subplot(gs[0])\n",
    "# ax2 = plt.subplot(gs[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, gridspec_kw={'width_ratios': [0.65, 1]})\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "#f.subplots_adjust(hspace=0)\n",
    "axs[0].imshow(torch.log(Y_sum.reshape(-1,1)+0.1))\n",
    "axs[1].imshow(jacobs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(jacobs_sum.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing whether the ordering checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TutorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ec1581b49403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTutorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_cache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_statistics_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TutorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "ds = TutorDataset(processed_data_path, matrix_cache_path, feature_statistics_path)\n",
    "dp = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ptv = dp['gen_pos_topo_vect']\n",
    "load_ptv = dp['load_pos_topo_vect']\n",
    "or_ptv = dp['line_or_pos_topo_vect']\n",
    "ex_ptv = dp['line_ex_pos_topo_vect']\n",
    "object_indices = np.argsort(np.concatenate([gen_ptv,load_ptv,or_ptv,ex_ptv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_ptv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dummy = len(gen_ptv)*[0]\n",
    "gen_dummy[-1] = 1000\n",
    "load_dummy = len(load_ptv)*[1]\n",
    "or_dummy = len(or_ptv)*[2]\n",
    "ex_dummy = len(ex_ptv)*[3]\n",
    "dummies = np.array(gen_dummy + load_dummy + or_dummy + ex_dummy)\n",
    "dummies[object_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummies_tensor = torch.cat([torch.tensor(d) for d in [gen_dummy,load_dummy,or_dummy,ex_dummy]])\n",
    "dummies_tensor[object_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
